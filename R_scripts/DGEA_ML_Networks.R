# Load libraries and data environment generated by running the script:
# "Preprocessing_and_QC.R"

# Optional clean-up of the environment:
# rm(ann_colors, annotation_for_heatmap, check_exprs, cm_RBE, dists, exprs_for_join,
# GEOsets, heatmap, KBZ_annotation_for_heatmap, KBZ_heatmap, KBZ_master, KBZ_mds, 
# KBZ_pca, KBZmds, masternormal, mds, normalmds, pca, plot_matrix, 
# RBE_annotation_for_heatmap, RBE_design, RBE_exprs, RBE_heatmap, RBE_mds, RBE_pca,
# z_exprs_for_join, hmcol, KBZdist, KBZPC1, KBZPC2, KBZPC3, normaldist, PC1, PC2, PC3)

##### Preparation #####
library(limma)
library(org.Hs.eg.db)
library(dplyr)
library(stringr)
library(tidyr)
library(EnhancedVolcano)
library(readr)
library(ggplot2)
library(ggpubr)
library(openxlsx)
library(enrichplot)
library(C50)
library(caret)
library(irr)
library(ipred)
library(adabag)
library(vcd)
library(randomForest)
library(pROC)
library(stringr)
library(kernlab)
library(glmnet)
library(MASS)
library(LiblineaR)
library(genefu)

# Enable parallel programming
library(doParallel)
system = Sys.info()['sysname']
cores = makeCluster(detectCores(), type='PSOCK')
cl = NULL
if (system == 'Windows') {
  cl = makeCluster(getOption('cl.cores', cores))
  registerDoParallel(cl)
  registerDoSEQ()
  on.exit(stopCluster(cl))
} else {
  options('mc.cores' = cores)
  registerDoParallel(cores)
}
# A function that outputs performance measures
err_metric=function(CM)
{
  TN =CM[1,1]
  TP =CM[2,2]
  FP =CM[1,2]
  FN =CM[2,1]
  precision =(TP)/(TP+FP)
  recall_score =(FP)/(FP+TN)
  
  f1_score=2*((precision*recall_score)/(precision+recall_score))
  accuracy_model  =(TP+TN)/(TP+TN+FP+FN)
  False_positive_rate =(FP)/(FP+TN)
  False_negative_rate =(FN)/(FN+TP)
  
  print(paste("Precision value of the model: ",round(precision,2)))
  print(paste("Accuracy of the model: ",round(accuracy_model,2)))
  print(paste("Recall value of the model: ",round(recall_score,2)))
  print(paste("False Positive rate of the model: ",round(False_positive_rate,2)))
  
  print(paste("False Negative rate of the model: ",round(False_negative_rate,2)))
  
  print(paste("f1 score of the model: ",round(f1_score,2)))
}

# A function that saves error metrics
get_err_metric=function(CM)
{
  TN =CM[1,1]
  TP =CM[2,2]
  FP =CM[1,2]
  FN =CM[2,1]
  precision =(TP)/(TP+FP)
  recall_score =(FP)/(FP+TN)
  
  f1_score=2*((precision*recall_score)/(precision+recall_score))
  accuracy_model  =(TP+TN)/(TP+TN+FP+FN)
  False_positive_rate =(FP)/(FP+TN)
  False_negative_rate =(FN)/(FN+TP)
  return(c(round(accuracy_model, 3), round(precision, 3), round(recall_score, 3),
           round(False_positive_rate, 3), round(False_negative_rate, 3),
           round(f1_score, 3)))
}


# Limma #####
z_design = model.matrix(~0 + Pheno_exprs$Response +
                          Pheno_exprs$Dataset +
                          Pheno_exprs$Timepoint_coded +
                          Pheno_exprs$pam50)[,c(1:12, 15:18)]
colnames(z_design) = c("Responder", "Non_responder", "C2", "C3", "E1_1", "E1_2", 
                       "E1_3", "E2", "E3", "E4_1", "E4_2", 
                       "T2", "HER2", "LumB", "LumA", "Normal")
rownames(z_design) = colnames(z_exprs)

z_cm = makeContrasts(RespvsNonresp = Responder - Non_responder,
                     levels = z_design)

KBZ_fit = lmFit(z_exprs, 
                design = z_design)
KBZ_fit2 = contrasts.fit(KBZ_fit, contrasts = z_cm)
KBZ_fit2 = eBayes(KBZ_fit2, robust = TRUE)
KBZ_results = summary(decideTests(KBZ_fit2))

KBZ_DE = as.data.frame(topTable(KBZ_fit2, adjust = "BH", number = Inf))
KBZ_DE$EntrezGene.ID = as.character(rownames(KBZ_DE))
KBZ_DE_mapped = KBZ_DE %>% left_join(official_df, by = "EntrezGene.ID") %>%
  dplyr::select(EntrezGene.ID, Gene.Symbol, everything())
rownames(KBZ_DE_mapped) = KBZ_DE_mapped$EntrezGene.ID

wb = createWorkbook()
addWorksheet(wb, "z_Limma")
writeData(wb, "z_Limma", KBZ_DE_mapped)
saveWorkbook(wb, "data/Output sets/Downstream/DGEA.xlsx", overwrite = TRUE)
gc()

# Volcano plots
# create custom key-value pairs for stat. sig genes (p.adj < 0.05) and n.s genes
keyvals.colour <- ifelse(
  KBZ_DE_mapped$logFC < 0 & KBZ_DE_mapped$adj.P.Val < 0.05, 'royalblue',
  ifelse(KBZ_DE_mapped$logFC > 0 & KBZ_DE_mapped$adj.P.Val < 0.05, 'red4',
         'grey'))
# keyvals.colour[is.na(keyvals.colour)] <- 'black'
names(keyvals.colour)[keyvals.colour == 'royalblue'] <- 'Down-regulated'
names(keyvals.colour)[keyvals.colour == 'red4'] <- 'Up-regulated'
names(keyvals.colour)[keyvals.colour == 'grey'] <- 'p.adj > 0.05'
KBZ_DE_mapped$aes = keyvals.colour

# Figure 1
volcano_KBZ = EnhancedVolcano(KBZ_DE_mapped,
                              lab = KBZ_DE_mapped[, "Gene.Symbol"],
                              caption = NULL,
                              x = 'logFC',
                              y = 'adj.P.Val',
                              title = NULL,
                              pCutoff = 0.05,
                              FCcutoff = 0,
                              cutoffLineType = "dashed",
                              cutoffLineWidth = 0.3,
                              cutoffLineCol = "black",
                              colCustom = keyvals.colour,
                              colAlpha = 0.7,
                              xlim = c(-0.5, 0.5),
                              ylim = c(0, 6),
                              ylab = bquote(bold(-log[10]("BH adj. p-value"))),
                              xlab = "\nDifferential expression",
                              pointSize = 1.5,
                              axisLabSize = 7,
                              subtitle = NULL,
                              labSize = 2,
                              selectLab = KBZ_DE_mapped[1:20, "Gene.Symbol"],
                              legendLabSize = 8,
                              legendIconSize = 4,
                              labFace = "bold",
                              boxedLabels = TRUE,
                              drawConnectors = TRUE,
                              typeConnectors = "closed",
                              arrowheads = FALSE,
                              widthConnectors = 0.3,
                              max.overlaps = Inf) +
  scale_y_continuous(limits = c(0, 7), breaks = seq(0, 7, 1))+
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_line(linewidth = 0.4),
        axis.title = element_text(face = "bold"),
        axis.line = element_line(colour = "black", linewidth = 0.4),
        axis.ticks = element_line(colour = "black", linewidth = 0.4),
        axis.ticks.length = unit(1, units = "mm"),
        legend.position = c(.8,.85),
        legend.title = element_blank(),
        legend.margin = ggplot2::margin(1, 1, 1, 1, unit = "mm"),
        legend.spacing.y = unit(1, units = "mm"),
        legend.spacing.x = unit(1, units = "mm"),
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))

volcano_KBZ
ggsave(filename = "Volcano.tiff",
       path = "data/Output sets/Downstream", 
       width = 100, height = 142, device = 'tiff', units = "mm",
       dpi = 700, compression = "lzw")
dev.off()

# Wide volcano
wide_volcano_KBZ = EnhancedVolcano(KBZ_DE_mapped,
                              lab = KBZ_DE_mapped[, "Gene.Symbol"],
                              caption = NULL,
                              x = 'logFC',
                              y = 'adj.P.Val',
                              title = NULL,
                              pCutoff = 0.05,
                              FCcutoff = 0,
                              cutoffLineType = "dashed",
                              cutoffLineWidth = 1,
                              cutoffLineCol = "black",
                              colCustom = keyvals.colour,
                              colAlpha = 0.7,
                              xlim = c(-0.5, 0.5),
                              ylim = c(0, 6),
                              ylab = bquote(bold(-log[10]("BH adj. p-value"))),
                              xlab = "\nDifferential expression",
                              pointSize = 1.5,
                              axisLabSize = 7,
                              subtitle = NULL,
                              labSize = 2,
                              selectLab = KBZ_DE_mapped[1:40, "Gene.Symbol"],
                              legendLabSize = 8,
                              legendIconSize = 4,
                              labFace = "bold",
                              boxedLabels = TRUE,
                              drawConnectors = TRUE,
                              typeConnectors = "closed",
                              arrowheads = FALSE,
                              max.overlaps = Inf)+
  scale_y_continuous(limits = c(0, 7), breaks = seq(0, 7, 1))+
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_line(linewidth = 0.4),
        axis.title = element_text(face = "bold"),
        axis.line = element_line(colour = "black", linewidth = 0.4),
        axis.ticks = element_line(colour = "black", linewidth = 0.4),
        axis.ticks.length = unit(1, units = "mm"),
        legend.position = c(.8,.85),
        legend.title = element_blank(),
        legend.margin = ggplot2::margin(1, 1, 1, 1, unit = "mm"),
        legend.spacing.y = unit(1, units = "mm"),
        legend.spacing.x = unit(1, units = "mm"),
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))

wide_volcano_KBZ
ggsave(filename = "Volcano_wide.tiff",
       path = "data/Output sets/Downstream", 
       width = 200, height = 142, device = 'tiff', units = "mm",
       dpi = 700, compression = "lzw")
dev.off()

# Volcano: poster size
volcano_KBZ_poster = EnhancedVolcano(KBZ_DE_mapped,
                              lab = KBZ_DE_mapped[, "Gene.Symbol"],
                              caption = NULL,
                              x = 'logFC',
                              y = 'adj.P.Val',
                              title = NULL,
                              pCutoff = 0.05,
                              FCcutoff = 0,
                              cutoffLineType = "dashed",
                              cutoffLineWidth = 0.6,
                              cutoffLineCol = "black",
                              colCustom = keyvals.colour,
                              colAlpha = 0.7,
                              xlim = c(-0.5, 0.5),
                              ylim = c(0, 6),
                              ylab = bquote(bold(-log[10]("BH adj. p-value"))),
                              xlab = "\nDifferential expression",
                              pointSize = 3,
                              axisLabSize = 14,
                              subtitle = NULL,
                              labSize = 3.5,
                              selectLab = KBZ_DE_mapped[1:20, "Gene.Symbol"],
                              legendLabSize = 15,
                              legendIconSize = 6,
                              labFace = "bold",
                              boxedLabels = TRUE,
                              drawConnectors = TRUE,
                              typeConnectors = "closed",
                              arrowheads = FALSE,
                              widthConnectors = 0.4,
                              max.overlaps = Inf)+
  scale_y_continuous(limits = c(0, 7), breaks = seq(0, 7, 1))+
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_line(linewidth = 0.8),
        axis.title = element_text(face = "bold"),
        axis.line = element_line(colour = "black", linewidth = 0.8),
        axis.ticks = element_line(colour = "black", linewidth = 0.8),
        axis.ticks.length = unit(2, units = "mm"),
        legend.position = c(.8,.85),
        legend.title = element_blank(),
        legend.margin = ggplot2::margin(2, 2, 2, 2, unit = "mm"),
        legend.spacing.y = unit(2, units = "mm"),
        legend.spacing.x = unit(2, units = "mm"),
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))

volcano_KBZ_poster
ggsave(filename = "Volcano_poster.tiff",
       path = "data/Output sets/Downstream", 
       width = 200, height = 284, device = 'tiff', units = "mm",
       dpi = 700, compression = "lzw")
dev.off()


# Mutations and census driver genes from COSMIC #####
# COSMIC data #####
COSMIC_pre = read.xlsx("COSMIC_BC_21042022.xlsx")
COSMIC = COSMIC_pre %>%
  dplyr::mutate(Ratio = Mutated.samples/Samples.tested) %>%
  dplyr::filter(Ratio > 0.01) %>% # filter for mutations with frequency of over 1%
  dplyr::filter(!grepl("\\.", Gene.name)) %>%
  dplyr::filter(!grepl("_", Gene.name))
COSMIC = COSMIC[order(COSMIC$Ratio, decreasing = TRUE), ] %>%
  distinct(Gene.name, .keep_all = TRUE); rm(COSMIC_pre)

# Common Gene symbols between COSMIC and the official gene symbols from the 
# org.Hs.eg.db database:

concordance = length(which(COSMIC$Gene.name %in% official_df$Gene.Symbol == TRUE))/nrow(COSMIC)
mismatch = COSMIC$Gene.name[which(COSMIC$Gene.name %in% official_df$Gene.Symbol == FALSE)]
a_concordance = length(which(mismatch %in% ID_Map$probe == TRUE))/length(mismatch)
discordance = mismatch[-which(mismatch %in% ID_Map$probe == TRUE)]
discordance

# discordance contains 21 genes some of which can be matched to Entrez ID's
# (https://www.genenames.org/tools/search/#!/?query=)

COSMIC$probe = COSMIC$Gene.name
COSMIC$probe[COSMIC$Gene.name == "36951"] = "RPL37P10"  # pseudogene
COSMIC$probe[COSMIC$Gene.name == "40603"] = "UPK1A-AS1" # long, non-coding RNA
COSMIC$probe[COSMIC$Gene.name == "37226"] = "PHGR1"     # coding
COSMIC$probe[COSMIC$Gene.name == "38047"] = "UQCRHP4"   # pseudogene
COSMIC$probe[COSMIC$Gene.name == "37681"] = "unclear" 
COSMIC$probe[COSMIC$Gene.name == "40057"] = "unclear" 
COSMIC$probe[COSMIC$Gene.name == "41833"] = "MIR4683"   # miRNA
COSMIC$probe[COSMIC$Gene.name == "40238"] = "unclear"
COSMIC$probe[COSMIC$Gene.name == "39326"] = "SNRPGP7"   # pseudogene
COSMIC$probe[COSMIC$Gene.name == "40787"] = "unclear"
COSMIC$probe[COSMIC$Gene.name == "38777"] = "USP9YP33"  # pseudogene
COSMIC$probe[COSMIC$Gene.name == "38961"] = "MIR3622B"  # miRNA
COSMIC$probe[COSMIC$Gene.name == "40422"] = "unclear"
COSMIC$probe[COSMIC$Gene.name == "39508"] = "ATP5MC1P5" # pseudogene
COSMIC$probe[COSMIC$Gene.name == "38412"] = "unclear"
COSMIC$probe[COSMIC$Gene.name == "39142"] = "unclear"
COSMIC$probe[COSMIC$Gene.name == "39692"] = "unclear"
COSMIC$probe[COSMIC$Gene.name == "37316"] = "MIR711"
COSMIC$probe[COSMIC$Gene.name == "38231"] = "MIR4253"
COSMIC$probe[COSMIC$Gene.name == "37865"] = "GLYATL1B"  # coding
COSMIC$probe[COSMIC$Gene.name == "37500"] = "RNVU1-7"   # snRNA

# further corrections
COSMIC$probe[COSMIC$Gene.name == "MPP6"] = "PALS2"    
# alias for two official symbols, 
# but MPHOSPH6 exists in COSMIC_pre so we believe this is for PALS2
COSMIC$probe[COSMIC$Gene.name == "DUSP27"] = "unclear" 
# unclear if it must match to STYXL2 or DUSP29

ID_Map$EntrezGene.ID = as.character(ID_Map$EntrezGene.ID)
COSMIC_annot = COSMIC %>%
  left_join(ID_Map, by = "probe") %>%
  dplyr::filter(!probe == "unclear") %>%
  left_join(official_df, by = "EntrezGene.ID") %>%
  dplyr::select(EntrezGene.ID, Gene.Symbol, Mutated.samples, Samples.tested, Ratio) %>%
  distinct()

COSMIC_annot$Ratio = as.numeric(COSMIC_annot$Ratio)
# Which of our genes are found to be mutated in more than 1% of COSMIC samples?
mut_Entrez = intersect(COSMIC_annot$EntrezGene.ID, 
          KBZ_DE_mapped$EntrezGene.ID[KBZ_DE_mapped$adj.P.Val < 0.05]) # 89 Entrez ID's
mut_HGNC = intersect(COSMIC_annot$Gene.Symbol, 
                     KBZ_DE_mapped$Gene.Symbol[KBZ_DE_mapped$adj.P.Val < 0.05])
mut_HGNC
# LARGE1, FAF1, EIF4G3, KIAA1549L, BCAR3
mut_HGNC_ratio = COSMIC_annot[COSMIC_annot$Gene.Symbol %in% mut_HGNC,]
mut_HGNC_ratio
# 0.1, 0.086, 0.074, 0.057, 0.052

# Cancer gene drivers
census = read.csv("COSMIC_census_21_04_2022.csv") %>%
  dplyr::rename(EntrezGene.ID = Entrez.GeneId, Gene.Symbol_COSMIC = Gene.Symbol) %>%
  dplyr::select(EntrezGene.ID, Gene.Symbol_COSMIC, Name, everything())
census$EntrezGene.ID = as.character(census$EntrezGene.ID)
census_annot = census %>% inner_join(official_df, by = "EntrezGene.ID")
census_annot_breast = census_annot %>%
  dplyr::filter(grepl("breast", Tumour.Types.Somatic.) | grepl("breast", Tumour.Types.Germline.))
general_drivers = census_annot %>% dplyr::select(Gene.Symbol, EntrezGene.ID)
BC_drivers = census_annot_breast %>% dplyr::select(Gene.Symbol, EntrezGene.ID)

# Concordance with our results
# Which genes are BC drivers?
BC_drivers # 43
# Which of them were in the 5672 genes we tested?
intersect(KBZ_DE_mapped$Gene.Symbol, BC_drivers$Gene.Symbol) # 23
# Which of them are significant?
intersect(KBZ_DE_mapped$EntrezGene.ID[KBZ_DE_mapped$adj.P.Val<0.05], BC_drivers$EntrezGene.ID)
# "10721"
intersect(KBZ_DE_mapped$Gene.Symbol[KBZ_DE_mapped$adj.P.Val<0.05], BC_drivers$Gene.Symbol)
# POLQ: polymerase theta is the only gene we find in common between our list of sig. genes
# and the list of census driver genes for breast cancer by COSMIC

# Intersection with general cancer drivers
# Which of them were in the 5672 genes we tested?
intersect(KBZ_DE_mapped$Gene.Symbol, general_drivers$Gene.Symbol) # 361
# Which of them are significant?
intersect(KBZ_DE_mapped$EntrezGene.ID[KBZ_DE_mapped$adj.P.Val<0.05], 
          general_drivers$EntrezGene.ID) # 14
# "10721" "6714"  "9401"  "29844" "7832"  "80204" "8243"  "9135"  "2271"  "472"
# "5424"  "596"  "8301"  "54894"
intersect(KBZ_DE_mapped$Gene.Symbol[KBZ_DE_mapped$adj.P.Val<0.05], 
          general_drivers$Gene.Symbol)
# "POLQ"   "SRC"    "RECQL4" "TFPT"   "BTG2"   "FBXO11" "SMC1A"  "RABEP1" "FH" "ATM"   
# "POLD1"  "BCL2"   "PICALM" "RNF43"

# ML #####

# Monte Carlo Consensus clustering #####
# Preparing data
library(M3C)
KBZ_Entrez_list = KBZ_DE_mapped %>% dplyr::filter(adj.P.Val < 0.05) %>%
  dplyr::select(EntrezGene.ID, Gene.Symbol)
data = as.data.frame(t(z_exprs))
siggenes = intersect(colnames(data), KBZ_Entrez_list$EntrezGene.ID)
data = data %>% dplyr::select(all_of(siggenes))
data$Sample.ID = rownames(data)

full_data = data %>%
  inner_join(Pheno_exprs %>% 
               dplyr::select(Sample.ID, Response, Timepoint_coded, 
                             Treatment, pam50, Mammaprint_risk, rorS_risk,
                             scmod1, IC10), by = "Sample.ID") %>%
  dplyr::rename(ID = Sample.ID, class = Response)
full_data$class = as.factor(full_data$class)
data = data %>% dplyr::select(-Sample.ID)
str_sub(colnames(data)[1:ncol(data)],0,0) = "X_"
mock_data = t(na.omit(data))
mock_data = as.data.frame(mock_data)
mock_full_data = na.omit(full_data) %>% dplyr::select(ID, class, Timepoint_coded, 
                                                      Treatment, pam50, 
                                                      Mammaprint_risk, rorS_risk,
                                                      scmod1, IC10)
mock_full_data$Timepoint_coded = as.factor(mock_full_data$Timepoint_coded)
mock_full_data$Treatment = as.factor(mock_full_data$Treatment)
mock_full_data$Mammaprint_risk = as.factor(mock_full_data$Mammaprint_risk)
mock_full_data$scmod1 = as.factor(mock_full_data$scmod1)
rownames(mock_full_data) = mock_full_data$ID
RNGversion("4.0.2")
mock = M3C(mock_data, des = mock_full_data, iters = 100, repsref = 250, 
           repsreal = 250, seed = 123, fsize = 18, lthick = 2, dotsize = 1.25)

# optimal K: 2
cluster_number = c(2,3,4,5,6,7,8,9,10)

chifit_resp_p = list()
chifit_resp_x  = list()
for (k in seq(2,10)){
  myresults = mock$realdataresults[[k]]$ordered_annotation
  chifit_resp = suppressWarnings(chisq.test(table(myresults[c('consensuscluster','class')])))
  chifit_resp_p[[k-1]] = chifit_resp$p.value
  chifit_resp_x[[k-1]] = chifit_resp$statistic
  rm(chifit_resp)
}

chifit_time_p = list()
chifit_time_x = list()
for (k in seq(2,10)){
  myresults = mock$realdataresults[[k]]$ordered_annotation
  chifit_time = suppressWarnings(chisq.test(table(myresults[c('consensuscluster','Timepoint_coded')])[,1:2])) # T1, T2 only
  chifit_time_p[[k-1]] = chifit_time$p.value
  chifit_time_x[[k-1]] = chifit_time$statistic
  rm(chifit_time)
}

chifit_pam50_p = list()
chifit_pam50_x = list()
for (k in seq(2,10)){
  myresults = mock$realdataresults[[k]]$ordered_annotation
  chifit_pam50 = suppressWarnings(chisq.test(table(myresults[c('consensuscluster','pam50')])))
  chifit_pam50_p[[k-1]] = chifit_pam50$p.value
  chifit_pam50_x[[k-1]] = chifit_pam50$statistic
  rm(chifit_pam50)
}

chifit_treat_p = list()
chifit_treat_x = list()
for (k in seq(2,10)){
  myresults = mock$realdataresults[[k]]$ordered_annotation
  chifit_treat = suppressWarnings(chisq.test(table(myresults[c('consensuscluster','Treatment')])))
  chifit_treat_p[[k-1]] = chifit_treat$p.value
  chifit_treat_x[[k-1]] = chifit_treat$statistic
  rm(chifit_treat)
}

chifit_mammaprint_p = list()
chifit_mammaprint_x = list()
for (k in seq(2,10)){
  myresults = mock$realdataresults[[k]]$ordered_annotation
  chifit_mammaprint = suppressWarnings(chisq.test(table(myresults[c('consensuscluster','Mammaprint_risk')])))
  chifit_mammaprint_p[[k-1]] = chifit_mammaprint$p.value
  chifit_mammaprint_x[[k-1]] = chifit_mammaprint$statistic
  rm(chifit_mammaprint)
}

chifit_rorS_p = list()
chifit_rorS_x = list()
for (k in seq(2,10)){
  myresults = mock$realdataresults[[k]]$ordered_annotation
  chifit_rorS = suppressWarnings(chisq.test(table(myresults[c('consensuscluster','rorS_risk')])))
  chifit_rorS_p[[k-1]] = chifit_rorS$p.value
  chifit_rorS_x[[k-1]] = chifit_rorS$statistic
  rm(chifit_rorS)
}

chifit_scmod1_p = list()
chifit_scmod1_x = list()
for (k in seq(2,10)){
  myresults = mock$realdataresults[[k]]$ordered_annotation
  chifit_scmod1 = suppressWarnings(chisq.test(table(myresults[c('consensuscluster','scmod1')])))
  chifit_scmod1_p[[k-1]] = chifit_scmod1$p.value
  chifit_scmod1_x[[k-1]] = chifit_scmod1$statistic
  rm(chifit_scmod1)
}

chifit_IC10_p = list()
chifit_IC10_x = list()
for (k in seq(2,10)){
  myresults = mock$realdataresults[[k]]$ordered_annotation
  chifit_IC10 = suppressWarnings(chisq.test(table(myresults[c('consensuscluster','IC10')])))
  chifit_IC10_p[[k-1]] = chifit_IC10$p.value
  chifit_IC10_x[[k-1]] = chifit_IC10$statistic
  rm(chifit_IC10)
}

# A function for Cramer's V statistic calculation (for K = 2)
cv.test = function(x, string) {
  CV = sqrt(chisq.test(x, correct=TRUE)$statistic / (sum(x) * min(dim(x) - 1 )))
  return(paste0("Cramer's V / Phi for ", string, ": ", round(as.numeric(CV), 3)))
}

cat(
  cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','class')]), "Response"), "\n",
  cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','Timepoint_coded')])[, 1:2], "Timepoint"), "\n",
  cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','pam50')]), "pam50"), "\n",
  cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','Treatment')]), "Treatment"), "\n",
  cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','Mammaprint_risk')]), "Mammaprint risk"), "\n",
  cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','rorS_risk')]), "rorS risk"), "\n",
  cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','scmod1')]), "scmod1"), "\n",
  cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','IC10')]), "IC10")
)

# According to: https://www.ibm.com/docs/en/cognos-analytics/11.1.0?topic=terms-cramrs-v
# Values below 0.2 are indicative of weak association, values between 0.2 and 0.6
# indicate intermediate effect size of association and values over 0.6 indicate 
# strong association

# Cramer's V / Phi for Response: 0.164 
# Cramer's V / Phi for Timepoint: 0.263 
# Cramer's V / Phi for pam50: 0.613 
# Cramer's V / Phi for Treatment: 0.032 
# Cramer's V / Phi for Mammaprint risk: 0.45 
# Cramer's V / Phi for rorS risk: 0.641 
# Cramer's V / Phi for scmod1: 0.46 
# Cramer's V / Phi for IC10: 0.494

# Bias-corrected Cramer's V calculation using package rcompanion:
unbiased.cv.test = function(x, string) {
  CV = rcompanion::cramerV(x, bias.correct = TRUE)
  return(paste0("Bias-corrected Cramer's V / Phi for ", string, ": ", round(as.numeric(CV), 3)))
}

cat(
  unbiased.cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','class')]), "Response"), "\n",
  unbiased.cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','Timepoint_coded')])[, 1:2], "Timepoint"), "\n",
  unbiased.cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','pam50')]), "pam50"), "\n",
  unbiased.cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','Treatment')]), "Treatment"), "\n",
  unbiased.cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','Mammaprint_risk')]), "Mammaprint risk"), "\n",
  unbiased.cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','rorS_risk')]), "rorS risk"), "\n",
  unbiased.cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','scmod1')]), "scmod1"), "\n",
  unbiased.cv.test(table(mock$realdataresults[[2]]$ordered_annotation[c('consensuscluster','IC10')]), "IC10")
)

# Bias-corrected Cramer's V / Phi for Response: 0.163 
# Bias-corrected Cramer's V / Phi for Timepoint: 0.264 
# Bias-corrected Cramer's V / Phi for pam50: 0.61 
# Bias-corrected Cramer's V / Phi for Treatment: 0.016 
# Bias-corrected Cramer's V / Phi for Mammaprint risk: 0.452 
# Bias-corrected Cramer's V / Phi for rorS risk: 0.64 
# Bias-corrected Cramer's V / Phi for scmod1: 0.457 
# Bias-corrected Cramer's V / Phi for IC10: 0.485

cluster_corr = as.data.frame(cbind(cluster_number, chifit_resp_p, chifit_treat_p,
                                   chifit_time_p, chifit_pam50_p, chifit_mammaprint_p,
                                   chifit_rorS_p, chifit_scmod1_p, chifit_IC10_p))
colnames(cluster_corr) = c("No. of clusters", "Response", "Treatment", "Timepoint", "pam50",
                           "Mammaprint_risk", "rorS_risk", "scmod1", "IC10")

Cluster = mock$realdataresults[[2]]$ordered_annotation$consensuscluster
# PCA clustering - Clusters
pca_clusters = pca(mock$realdataresults[[2]]$ordered_data,
                   labels = mock$realdataresults[[2]]$ordered_annotation$consensuscluster,
                   legendtextsize = 2, legendtitle = "Consensus Subtype", axistextsize = 4,
                   dotsize = 0.1)+
  aes(shape = as.character(Cluster), size = as.character(Cluster),
      alpha = as.character(Cluster), color = as.character(Cluster)) +
  scale_size_manual(name = "Consensus Subtype", values = c(0.1, 0.1), labels = c("NAT-responsive",
                                                                                   "NAT-neutral")) +
  scale_alpha_manual(name = "Consensus Subtype", values = c(0.7, 0.7), labels = c("NAT-responsive",
                                                                                  "NAT-neutral")) +
  scale_shape_manual(name = "Consensus Subtype", values = c(16,17), labels = c("NAT-responsive",
                                                                               "NAT-neutral"))+
  scale_color_manual(name = "Consensus Subtype", values = c("#68abb8", "#f2855d"), labels = c("NAT-responsive",
                                                                               "NAT-neutral"))+
  geom_segment(aes(x = 18, y = 11, xend = 18, yend = 18),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  geom_segment(aes(x = 18, y = 11, xend = 23, yend = 11),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  theme(panel.border = element_rect(linewidth = 0.2),
        plot.title = element_text(size = 5, face = "bold"),
        legend.title = element_text(face = "bold"),
        axis.title.x = element_text(size = 4, face = "bold"),
        axis.title.y = element_text(size = 4, face = "bold"),
        axis.ticks = element_line(linewidth = 0.15),
        legend.background = element_rect(fill = "white", linetype = "solid"),
        legend.position = c(0.90, 0.86),
        legend.key.size = unit(0.1, "cm"),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"))+
  labs(title = "PCA plot: the two clusters") +
  guides(size = "none", alpha = "none")
pca_clusters
ggsave(filename = "Cluster_PCA.tiff",
       path = "data/Output sets/Downstream", 
       width = 1920, height = 1080, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

# PCA clustering - Response
pca_response = pca(mock$realdataresults[[2]]$ordered_data,
                   labels = mock$realdataresults[[2]]$ordered_annotation$class,
                   axistextsize = 4, legendtextsize = 2, dotsize = 0.1) +
  aes(shape = as.character(Cluster), size = as.character(Cluster),
      alpha = as.character(Cluster), color = as.character(Response)) +
  scale_size_manual(name = "Consensus Subtype", values = c(0.1, 0.1), labels = c("NAT-responsive",
                                                                                   "NAT-neutral")) +
  scale_alpha_manual(name = "Consensus Subtype", values = c(0.6, 0.6), labels = c("NAT-responsive",
                                                                                  "NAT-neutral")) +
  scale_shape_manual(name = "Consensus Subtype", values = c(16,17), labels = c("NAT-responsive",
                                                                               "NAT-neutral"))+
  scale_color_manual(name = "Response", limits = c("Responder", "Non_responder"),
                     values = c("dodgerblue4", "deeppink4"), 
                     labels = c("Responder",  "Non-responder"))+
  geom_segment(aes(x = 18, y = 10, xend = 18, yend = 19),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  geom_segment(aes(x = 18, y = 10, xend = 23, yend = 10),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  theme(panel.border = element_rect(linewidth = 0.2),
        plot.title = element_text(size = 5, face = "bold"),
        legend.title = element_text(face = "bold"),
        axis.title.x = element_text(size = 4, face = "bold"),
        axis.title.y = element_text(size = 4, face = "bold"),
        axis.ticks = element_line(linewidth = 0.15),
        legend.background = element_rect(fill = "white", linetype = "solid"),
        legend.position = c(0.90, 0.84),
        legend.key.size = unit(0.1, "cm"),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"))+
  labs(title = "PCA plot: clusters and response") +
  guides(size = "none", alpha = "none")
pca_response
ggsave(filename = "response_cluster_PCA.tiff",
       path = "data/Output sets/Downstream", 
       width = 1920, height = 1080, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

# PCA clustering - pam50 subtypes
pca_pam50 = pca(mock$realdataresults[[2]]$ordered_data,
                labels = mock$realdataresults[[2]]$ordered_annotation$pam50,
                axistextsize = 4, legendtextsize = 2, dotsize = 0.1) +
  aes(shape = as.character(Cluster), size = as.character(Cluster),
      alpha = as.character(Cluster), color = as.character(pam50)) +
  scale_size_manual(name = "Consensus Subtype", values = c(0.1, 0.1), labels = c("NAT-responsive",
                                                                                 "NAT-neutral")) +
  scale_alpha_manual(name = "Consensus Subtype", values = c(0.7, 0.7), labels = c("NAT-responsive",
                                                                                  "NAT-neutral")) +
  scale_shape_manual(name = "Consensus Subtype", values = c(16,17), labels = c("NAT-responsive",
                                                                               "NAT-neutral"))+
  scale_color_manual(name = "pam50 subtype", limits = c("Basal", "LumB", "LumA", "Her2", "Normal"),
                     values = c("red4", "skyblue", "darkblue", "violet", "lightgreen"), 
                     labels = c("Basal", "Luminal B", "Luminal A", "HER2+", "Normal-like"))+
  geom_segment(aes(x = 18, y = 5.5, xend = 18, yend = 18),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  geom_segment(aes(x = 18, y = 5.5, xend = 23, yend = 5.5),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  theme(panel.border = element_rect(linewidth = 0.2),
        plot.title = element_text(size = 5, face = "bold"),
        legend.title = element_text(face = "bold"),
        axis.title.x = element_text(size = 4, face = "bold"),
        axis.title.y = element_text(size = 4, face = "bold"),
        axis.ticks = element_line(linewidth = 0.15),
        legend.background = element_rect(fill = "white", linetype = "solid"),
        legend.position = c(0.90, 0.78),
        legend.key.size = unit(0.1, "cm"),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"))+
  labs(title = "PCA plot: clusters and pam50") +
  guides(size = "none", alpha = "none")

pca_pam50
ggsave(filename = "pam50_cluster_PCA.tiff",
       path = "data/Output sets/Downstream", 
       width = 1920, height = 1080, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

# PCA clustering - Timepoints
pca_time = pca(mock$realdataresults[[2]]$ordered_data,
               labels = mock$realdataresults[[2]]$ordered_annotation$Timepoint_coded,
               axistextsize = 4, legendtextsize = 2, dotsize = 0.1)+
  aes(shape = as.character(Cluster), size = as.character(Cluster),
      alpha = as.character(Cluster), color = as.character(Timepoint)) +
  scale_size_manual(name = "Consensus Subtype", values = c(0.1, 0.1), labels = c("NAT-responsive",
                                                                                 "NAT-neutral")) +
  scale_alpha_manual(name = "Consensus Subtype", values = c(0.6, 0.6), labels = c("NAT-responsive",
                                                                                  "NAT-neutral")) +
  scale_shape_manual(name = "Consensus Subtype", values = c(16,17), labels = c("NAT-responsive",
                                                                               "NAT-neutral"))+
  scale_color_manual(name = "Timepoint", limits = c("T1", "T2"),
                     values = c("goldenrod2", "purple4"), 
                     labels = c("Pre-treatment",  "On-treatment"))+
  geom_segment(aes(x = 18, y = 10, xend = 18, yend = 19),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  geom_segment(aes(x = 18, y = 10, xend = 23, yend = 10),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  theme(panel.border = element_rect(linewidth = 0.2),
        plot.title = element_text(size = 5, face = "bold"),
        legend.title = element_text(face = "bold"),
        axis.title.x = element_text(size = 4, face = "bold"),
        axis.title.y = element_text(size = 4, face = "bold"),
        axis.ticks = element_line(linewidth = 0.15),
        legend.background = element_rect(fill = "white", linetype = "solid"),
        legend.position = c(0.90, 0.84),
        legend.key.size = unit(0.1, "cm"),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"))+
  labs(title = "PCA plot: clusters and timepoint")+
  guides(size = "none", alpha = "none")
pca_time
ggsave(filename = "timepoint_cluster_PCA.tiff",
       path = "data/Output sets/Downstream", 
       width = 1920, height = 1080, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")  
dev.off()

# PCA clustering - rors risk
pca_rorS = pca(mock$realdataresults[[2]]$ordered_data,
               labels = mock$realdataresults[[2]]$ordered_annotation$rorS_risk,
               axistextsize = 4, legendtextsize = 2, dotsize = 0.1) +
  aes(shape = as.character(Cluster), size = as.character(Cluster),
      alpha = as.character(Cluster), color = as.character(rorS_risk)) +
  scale_size_manual(name = "Consensus Subtype", values = c(0.1, 0.1), labels = c("NAT-responsive",
                                                                                 "NAT-neutral")) +
  scale_alpha_manual(name = "Consensus Subtype", values = c(0.6, 0.6), labels = c("NAT-responsive",
                                                                                  "NAT-neutral")) +
  scale_shape_manual(name = "Consensus Subtype", values = c(16,17), labels = c("NAT-responsive",
                                                                               "NAT-neutral"))+
  scale_color_manual(name = "Risk of Relapse", limits = c("High", "Intermediate", "Low"),
                     values = c("red4", "orange", "chartreuse4"), 
                     labels = c("High",  "Intermediate", "Low"))+
  geom_segment(aes(x = 18, y = 9, xend = 18, yend = 19),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  geom_segment(aes(x = 18, y = 9, xend = 23, yend = 9),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  theme(panel.border = element_rect(linewidth = 0.2),
        plot.title = element_text(size = 5, face = "bold"),
        legend.title = element_text(face = "bold"),
        axis.title.x = element_text(size = 4, face = "bold"),
        axis.title.y = element_text(size = 4, face = "bold"),
        axis.ticks = element_line(linewidth = 0.15),
        legend.background = element_rect(fill = "white", linetype = "solid"),
        legend.position = c(0.90, 0.83),
        legend.key.size = unit(0.1, "cm"),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"))+
  labs(title = "PCA plot: clusters and rorS risk")+
  guides(size = "none", alpha = "none")
pca_rorS
ggsave(filename = "rorS_cluster_PCA.tiff",
       path = "data/Output sets/Downstream", 
       width = 1920, height = 1080, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")  
dev.off()

# PCA clustering - Mammaprint risk
pca_mammaprint = pca(mock$realdataresults[[2]]$ordered_data,
                     labels = factor(mock$realdataresults[[2]]$ordered_annotation$Mammaprint_risk,
                                     levels = c(0,1), labels = c("No risk", "Risk")),
                     axistextsize = 4, legendtextsize = 2, dotsize = 0.1)+
  aes(shape = as.character(Cluster), size = as.character(Cluster),
      alpha = as.character(Cluster), color = as.character(Mammaprint_risk)) +
  scale_size_manual(name = "Consensus Subtype", values = c(0.1, 0.1), labels = c("NAT-responsive",
                                                                                 "NAT-neutral")) +
  scale_alpha_manual(name = "Consensus Subtype", values = c(0.6, 0.6), labels = c("NAT-responsive",
                                                                                  "NAT-neutral")) +
  scale_shape_manual(name = "Consensus Subtype", values = c(16, 17), labels = c("NAT-responsive",
                                                                               "NAT-neutral"))+
  scale_color_manual(name = "Mammaprint risk", limits = c("Risk", "No risk"),
                     values = c("red3", "green4"), 
                     labels = c("Risk", "No risk"))+
  geom_segment(aes(x = 18, y = 10, xend = 18, yend = 19),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  geom_segment(aes(x = 18, y = 10, xend = 23, yend = 10),
               alpha = 0.7, color = "grey", linewidth = 0.1)+
  theme(panel.border = element_rect(linewidth = 0.2),
        plot.title = element_text(size = 5, face = "bold"),
        legend.title = element_text(face = "bold"),
        axis.title.x = element_text(size = 4, face = "bold"),
        axis.title.y = element_text(size = 4, face = "bold"),
        axis.ticks = element_line(linewidth = 0.15),
        legend.background = element_rect(fill = "white", linetype = "solid"),
        legend.position = c(0.90, 0.84),
        legend.key.size = unit(0.1, "cm"),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"))+
  labs(title = "PCA plot: clusters and Mammaprint risk")+
  guides(size = "none", alpha = "none")
pca_mammaprint
ggsave(filename = "mammaprint_cluster_PCA.tiff",
       path = "data/Output sets/Downstream", 
       width = 1920, height = 1080, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")  
dev.off()

# PCA multiplot
ggarrange(pca_clusters, pca_pam50, 
          pca_response, pca_time,
          pca_mammaprint, pca_rorS, 
          ncol = 2, nrow = 3, labels = c("A", "B", "C", "D", "E", "F"),
          font.label = list(size = 8, face = "bold", color ="black"))
ggsave(filename = "Multiplot_cluster_PCA.tiff",
       path = "data/Output sets/Downstream", 
       width = 3840, height = 3240, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

Cluster_anno = Cluster
rm(Cluster, pca_clusters, pca_response,
   pca_pam50, pca_time,
   pca_rorS, pca_mammaprint); gc()

# Consensus index plot
ci_plot = ggplot(mock[["plots"]][[1]][["data"]], aes(x = consensusindex, y = CDF,
                                                     group = k, alpha = 0.7))+
  geom_line(aes(color = factor(k)), linewidth = 0.5)+
  theme_bw()+
  theme(panel.border = element_rect(linewidth = 0.2),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title = element_text(size = 5, face = "bold"),
        legend.title = element_text(face = "bold", size = 4),
        legend.text = element_text(size = 3),
        legend.key.size = unit(0.2, "cm"),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"),
        axis.title.x = element_text(size = 4, face = "bold"),
        axis.title.y = element_text(size = 4, face = "bold"),
        axis.ticks = element_line(linewidth = 0.15),
        axis.text.x = element_text(size = 4),
        axis.text.y = element_text(size = 4))+
  labs(y = "Cumulative Distribution Function (CDF)",
       x = "Consensus Index",
       title = "Real Data")+
  guides(color = guide_legend(title = "K"), linewidth = "none", alpha = "none")
ci_plot
ggsave(filename = "Consensus_index.tiff",
       path = "data/Output sets/Downstream", 
       width = 1920, height = 1080, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

# Entropy plot
entropy = ggplot(mock[["plots"]][[2]][["data"]], aes(x = K, y = PAC_SCORE, alpha = 0.7))+
  geom_line(aes(color = "#7c1d6f"), linewidth = 0.5)+
  scale_x_continuous(limits = c(2, 10), breaks = seq(2, 10, 1))+
  theme_bw()+
  theme(panel.border = element_rect(linewidth = 0.2),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title = element_text(size = 5, face = "bold", vjust = 0.5, hjust = 0.5),
        legend.title = element_text(face = "bold", size = 4),
        legend.text = element_text(size = 3),
        legend.key.size = unit(0.2, "cm"),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"),
        axis.title.x = element_text(size = 4, face = "bold"),
        axis.title.y = element_text(size = 4, face = "bold"),
        axis.ticks = element_line(linewidth = 0.15),
        axis.text.x = element_text(size = 4),
        axis.text.y = element_text(size = 4))+
  labs(y = "Entropy",
       x = "K",
       title = "Real Data")+
  guides(color = "none", alpha = "none")
entropy
ggsave(filename = "Entropy.tiff",
       path = "data/Output sets/Downstream", 
       width = 1920, height = 1080, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

# Statistical significance of clusters
statsig_clust = ggplot(mock[["plots"]][[3]][["data"]], aes(x = K, y = P_SCORE, 
                                                           color = P_SCORE < -log10(0.05)))+
  geom_point(size = 1.5, alpha = 0.6)+
  geom_hline(yintercept = -log10(0.05), linetype = "dashed", linewidth = 0.2)+
  scale_x_continuous(limits = c(2, 10), breaks = seq(2, 10, 1))+
  scale_color_manual(name = "Color",
                     values = c("#6c2167", "grey"),
                     labels = c("p < 0.05", "p > 0.05")) +
  theme_bw()+
  theme(panel.border = element_rect(linewidth = 0.2),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title = element_text(size = 5, face = "bold"),
        axis.title.x = element_text(size = 4, face = "bold"),
        axis.title.y = element_text(size = 4, face = "bold"),
        axis.ticks = element_line(linewidth = 0.15),
        axis.text.x = element_text(size = 4),
        axis.text.y = element_text(size = 4),
        legend.title = element_text(face = "bold", size = 4),
        legend.text = element_text(size = 3),
        legend.key.size = unit(0.2, "cm"),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"))+
  labs(title = "Statistical significance of different values of K",
       y = bquote(bold(-log[10]("p"))))
statsig_clust
ggsave(filename = "Stat_Sig.tiff",
       path = "data/Output sets/Downstream", 
       width = 1920, height = 1080, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

# RCSI plot
rcsi = ggplot(as.data.frame(mock[["scores"]]), aes(x = mock$scores$K,
                                            y = mock$scores$RCSI))+
  geom_line(size = 0.3, color = "violet")+
  geom_errorbar(aes(ymin = mock$scores$RCSI - mock$scores$RCSI_SE,
                    ymax = mock$scores$RCSI + mock$scores$RCSI_SE,
                    color = "deeppink3"), width = 0.2, size = 0.1)+
  geom_point(size = 0.05, color ="deeppink3")+
  scale_x_continuous(limits = c(1.9, 10.1), breaks = seq(2, 10, 1))+
  scale_y_continuous(limits = c(0, 0.7), breaks = seq(0, 0.7, 0.1))+
  theme(plot.title = element_text(size = 5, face = "bold"),
        axis.title.x = element_text(size = 4, face = "bold"),
        axis.title.y = element_text(size = 4, face = "bold"),
        axis.ticks = element_line(linewidth = 0.15),
        axis.text.x = element_text(size = 4),
        axis.text.y = element_text(size = 4),
        legend.position = "none",
        panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid = element_blank(),
        axis.line = element_line(linewidth = 0.2))+
  labs(title = "Relative Cluster Stability Index vs. number of clusters K",
       x = "K", y = "RCSI")
rcsi
ggsave(filename = "RCSI.tiff", path = "data/Output sets/Downstream", 
       width = 1920, height = 1080, device='tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

kmwb = createWorkbook()
addWorksheet(kmwb, "Results")
writeData(kmwb, "Results", mock[["realdataresults"]][[2]][["ordered_annotation"]])
addWorksheet(kmwb, "Chisq.test")
writeData(kmwb, "Chisq.test", cluster_corr)
addWorksheet(kmwb, "Performance")
writeData(kmwb, "Performance", mock[["scores"]])
saveWorkbook(kmwb, file = "data/Output sets/Downstream/Clustering.xlsx",
             overwrite = TRUE); rm(kmwb); gc()

rm(KBZ_Entrez_list, data, siggenes, full_data); gc()

cluster_results = data.frame(rownames(mock[["realdataresults"]][[2]][["ordered_annotation"]]), 
                             mock[["realdataresults"]][[2]][["ordered_annotation"]][["consensuscluster"]])
# 2: optimal number of clusters
colnames(cluster_results) = c("Sample.ID", "Cluster")

# Graphs for the clusters and the variables #####
plotdata = mock[["realdataresults"]][[2]][["ordered_annotation"]]
colnames(plotdata) = c("Consensus Subtype", "Response", "Timepoint", "Treatment",
                       "pam50", "Mammaprint risk", "rorS risk", "scmod1", "iC10")
plotdata$Response = factor(plotdata$Response, levels = c("Responder", "Non_responder"),
                           labels = c("Responder", "Non-responder"))
plotdata$`Mammaprint risk` = factor(plotdata$`Mammaprint risk`, levels = c(0,1),
                                    labels = c("No risk", "Risk"))
plotdata$Timepoint = factor(plotdata$Timepoint, levels = c("T1", "T2"),
                            labels = c("Pre-treatment", "On-treatment"))

# Custom color scales
# response
scale_fill_response = function(...){
  library(scales)
  discrete_scale("fill","sjs",manual_pal(values = c("dodgerblue4", "deeppink4")), ...)
}

# treatment
scale_fill_treatment = function(...){
  library(scales)
  discrete_scale("fill","sjs",manual_pal(values = c("paleturquoise3", "sienna2")), ...)
}

# pam50
scale_fill_pam50 = function(...){
  library(scales)
  discrete_scale("fill","sjs",manual_pal(values = c("red4", "violet", "skyblue",
                                                    "darkblue", "lightgreen")), ...)
}

# scmod1
scale_fill_scmod1 = function(...){
  library(scales)
  discrete_scale("fill","sjs",manual_pal(values = c("red4", "skyblue",
                                                    "darkblue", "violet")), ...)
}

# rorS
scale_fill_rorS = function(...){
  library(scales)
  discrete_scale("fill","sjs",manual_pal(values = c("chartreuse4", "orange", "red4")), ...)
}

# Mammaprint
scale_fill_mammaprint = function(...){
  library(scales)
  discrete_scale("fill","sjs",manual_pal(values = c("green4", "red3")), ...)
}

# IC10
scale_fill_ic10 = function(...){
  library(scales)
  discrete_scale("fill","sjs",manual_pal(values = c("pink3", "red", 
                                                    "red4", "beige", 
                                                    "aliceblue", "cadetblue3", 
                                                    "darkmagenta", "hotpink4", 
                                                    "lightpink2", "mistyrose1")), ...)
}

# Timepoint
scale_fill_timepoint = function(...){
  library(scales)
  discrete_scale("fill","sjs",manual_pal(values = c("goldenrod2", "purple4")), ...)
}

# response
barchart_resp = ggplot(plotdata, aes(fill=Response, x=`Consensus Subtype`)) + 
  geom_bar(position="stack", stat="count", width = 0.4) +
  scale_y_continuous(limits = c(0,675), breaks = seq(0, 675, 100)) +
  scale_fill_response() +
  labs(y = "Number of samples") +
  annotate("text", x = 1.5, y = 640, size = 1.8,
           label = bquote(italic(X^2) == .(round(chifit_resp_x[[1]], 2))))+
  annotate("text", x = 1.5, y = 590, size = 1.8,
           parse = if (chifit_resp_p[[1]] < 10e-5) { TRUE } else { FALSE },
           label = if (chifit_resp_p[[1]] < 10e-5) {
             "italic(p) < 10^-5"
           } else {
             bquote(italic(p) == .(round(chifit_resp_p[[1]], 2)))
           }) +
  geom_rect(aes(xmin = 1.1, xmax = 1.9, ymin = 555, ymax = 670),
            fill = "transparent", color = "black", linewidth = 0.4) +
  theme(panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(size = 8, face = "bold"),
        legend.key.size = unit(0.35, "cm"),
        legend.text = element_text(size = 6),
        legend.title = element_text(face = "bold", size  = 6))

# treatment
barchart_treat = ggplot(plotdata, aes(fill=Treatment, x=`Consensus Subtype`)) + 
  geom_bar(position="stack", stat="count", width = 0.4) +
  scale_y_continuous(limits = c(0,675), breaks = seq(0, 675, 100)) +
  scale_fill_treatment() +
  labs(y = "Number of samples") +
  annotate("text", x = 1.5, y = 640, size = 1.8, 
           label = bquote(italic(X^2) == .(round(chifit_treat_x[[1]], 2))))+
  annotate("text", x = 1.5, y = 590, size = 1.8,
           parse = if (chifit_treat_p[[1]] < 10e-5) { TRUE } else { FALSE },
           label = if (chifit_treat_p[[1]] < 10e-5) {
             "italic(p) < 10^-5"
           } else {
             bquote(italic(p) == .(round(chifit_treat_p[[1]], 2)))
           }) +
  geom_rect(aes(xmin = 1.1, xmax = 1.9, ymin = 555, ymax = 670),
            fill = "transparent", color = "black", linewidth = 0.4) +
  theme(panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(size = 8, face = "bold"),
        legend.key.size = unit(0.35, "cm"),
        legend.text = element_text(size = 6),
        legend.title = element_text(face = "bold", size  = 6))

# pam50
barchart_pam50 = ggplot(plotdata, aes(fill=pam50, x=`Consensus Subtype`)) + 
  geom_bar(position="stack", stat="count", width = 0.4) +
  scale_y_continuous(limits = c(0,675), breaks = seq(0, 675, 100)) +
  scale_fill_pam50() +
  labs(y = "Number of samples") +
  annotate("text", x = 1.5, y = 640, size = 1.8, 
           label = bquote(italic(X^2) == .(round(chifit_pam50_x[[1]], 2))))+
  annotate("text", x = 1.5, y = 590, size = 1.8,
           parse = if (chifit_pam50_p[[1]] < 10e-5) { TRUE } else { FALSE },
           label = if (chifit_pam50_p[[1]] < 10e-5) {
             "italic(p) < 10^-5"
           } else {
             bquote(italic(p) == .(round(chifit_pam50_p[[1]], 2)))
           }) +
  geom_rect(aes(xmin = 1.1, xmax = 1.9, ymin = 555, ymax = 670),
            fill = "transparent", color = "black", linewidth = 0.4) +
  theme(panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(size = 8, face = "bold"),
        legend.key.size = unit(0.35, "cm"),
        legend.text = element_text(size = 6),
        legend.title = element_text(face = "bold", size  = 6))


# scmod1
barchart_scmod1 = ggplot(plotdata, aes(fill=scmod1, x=`Consensus Subtype`)) + 
  geom_bar(position="stack", stat="count", width = 0.4) +
  scale_y_continuous(limits = c(0,675), breaks = seq(0, 675, 100)) +
  scale_fill_scmod1() +
  labs(y = "Number of samples") +
  annotate("text", x = 1.5, y = 640, size = 1.8, 
           label = bquote(italic(X^2) == .(round(chifit_scmod1_x[[1]], 2))))+
  annotate("text", x = 1.5, y = 590, size = 1.8,
           parse = if (chifit_scmod1_p[[1]] < 10e-5) { TRUE } else { FALSE },
           label = if (chifit_scmod1_p[[1]] < 10e-5) {
             "italic(p) < 10^-5"
           } else {
             bquote(italic(p) == .(round(chifit_scmod1_p[[1]], 2)))
           }) +
  geom_rect(aes(xmin = 1.1, xmax = 1.9, ymin = 555, ymax = 670),
            fill = "transparent", color = "black", linewidth = 0.4) +
  theme(panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(size = 8, face = "bold"),
        legend.key.size = unit(0.35, "cm"),
        legend.text = element_text(size = 6),
        legend.title = element_text(face = "bold", size  = 6))

# rorS
barchart_rorS = ggplot(plotdata, aes(fill=`rorS risk`, x=`Consensus Subtype`)) + 
  geom_bar(position="stack", stat="count", width = 0.4) +
  scale_y_continuous(limits = c(0,675), breaks = seq(0, 675, 100)) +
  scale_fill_rorS() +
  labs(y = "Number of samples") +
  annotate("text", x = 1.5, y = 640, size = 1.8, 
           label = bquote(italic(X^2) == .(round(chifit_rorS_x[[1]], 2))))+
  annotate("text", x = 1.5, y = 590, size = 1.8,
           parse = if (chifit_rorS_p[[1]] < 10e-5) { TRUE } else { FALSE },
           label = if (chifit_rorS_p[[1]] < 10e-5) {
             "italic(p) < 10^-5"
           } else {
             bquote(italic(p) == .(round(chifit_rorS_p[[1]], 2)))
           }) +
  geom_rect(aes(xmin = 1.1, xmax = 1.9, ymin = 555, ymax = 670),
            fill = "transparent", color = "black", linewidth = 0.4) +
  theme(panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(size = 8, face = "bold"),
        legend.key.size = unit(0.35, "cm"),
        legend.text = element_text(size = 6),
        legend.title = element_text(face = "bold", size  = 6))

# Mammaprint
barchart_mammaprint = ggplot(plotdata, aes(fill=`Mammaprint risk`, x=`Consensus Subtype`)) + 
  geom_bar(position="stack", stat="count", width = 0.4) +
  scale_y_continuous(limits = c(0,675), breaks = seq(0, 675, 100)) +
  scale_fill_mammaprint() +
  labs(y = "Number of samples") +
  annotate("text", x = 1.5, y = 640, size = 1.8, 
           label = bquote(italic(X^2) == .(round(chifit_mammaprint_x[[1]], 2))))+
  annotate("text", x = 1.5, y = 590, size = 1.8,
           parse = if (chifit_mammaprint_p[[1]] < 10e-5) { TRUE } else { FALSE },
           label = if (chifit_mammaprint_p[[1]] < 10e-5) {
             "italic(p) < 10^-5"
           } else {
             bquote(italic(p) == .(round(chifit_mammaprint_p[[1]], 2)))
           }) +
  geom_rect(aes(xmin = 1.1, xmax = 1.9, ymin = 555, ymax = 670),
            fill = "transparent", color = "black", linewidth = 0.4) +
  theme(panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(size = 8, face = "bold"),
        legend.key.size = unit(0.35, "cm"),
        legend.text = element_text(size = 6),
        legend.title = element_text(face = "bold", size  = 6))

# IC10
barchart_ic10 = ggplot(plotdata, aes(fill=`iC10`, x=`Consensus Subtype`)) + 
  geom_bar(position="stack", stat="count", width = 0.4) +
  scale_y_continuous(limits = c(0,675), breaks = seq(0, 675, 100)) +
  scale_fill_ic10() +
  labs(y = "Number of samples") +
  annotate("text", x = 1.5, y = 640, size = 1.8, 
           label = bquote(italic(X^2) == .(round(chifit_IC10_x[[1]], 2))))+
  annotate("text", x = 1.5, y = 590, size = 1.8,
           parse = if (chifit_IC10_p[[1]] < 10e-5) { TRUE } else { FALSE },
           label = if (chifit_IC10_p[[1]] < 10e-5) {
             "italic(p) < 10^-5"
           } else {
             bquote(italic(p) == .(round(chifit_IC10_p[[1]], 2)))
           }) +
  geom_rect(aes(xmin = 1.1, xmax = 1.9, ymin = 555, ymax = 670),
            fill = "transparent", color = "black", linewidth = 0.4) +
  theme(panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(size = 8, face = "bold"),
        legend.key.size = unit(0.35, "cm"),
        legend.text = element_text(size = 6),
        legend.title = element_text(face = "bold", size  = 6))

# Timepoint
barchart_timepoint = ggplot(plotdata, aes(fill=Timepoint, x=`Consensus Subtype`)) + 
  geom_bar(position="stack", stat="count", width = 0.4) +
  scale_y_continuous(limits = c(0,675), breaks = seq(0, 675, 100)) +
  scale_fill_timepoint() +
  labs(y = "Number of samples") +
  annotate("text", x = 1.5, y = 640, size = 1.8, 
           label = bquote(italic(X^2) == .(round(chifit_time_x[[1]], 2))))+
  annotate("text", x = 1.5, y = 590, size = 1.8,
           parse = if (chifit_time_p[[1]] < 10e-5) { TRUE } else { FALSE },
           label = if (chifit_time_p[[1]] < 10e-5) {
             'italic(p) < 10^-5'
           } else {
             bquote(italic(p) == .(round(chifit_time_p[[1]], 2)))
           }) +
  geom_rect(aes(xmin = 1.1, xmax = 1.9, ymin = 555, ymax = 670),
            fill = "transparent", color = "black", linewidth = 0.4) +
  theme(panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid = element_blank(),
        axis.line = element_line(),
        axis.title = element_text(size = 8, face = "bold"),
        legend.key.size = unit(0.35, "cm"),
        legend.text = element_text(size = 6),
        legend.title = element_text(face = "bold", size  = 6))

# Multiplot (TIFF) - bar charts
ggarrange(barchart_treat, barchart_pam50,
          barchart_rorS, barchart_timepoint,
          barchart_resp, barchart_scmod1,
          barchart_mammaprint, barchart_ic10, 
          ncol = 2, nrow = 4, labels = c("A", "B", "C", "D", "E", "F", "G", "H"),
          font.label = list(size = 8, face = "bold", color ="black"))
ggsave(filename = "Multiplot_cluster_barcharts.tiff",
       path = "data/Output sets/Downstream", 
       width = 4612, height = 6000, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

# Additional DGEA plots #####
# Heatmap of diff. expressed genes (p.adj < 0.05) versus samples:
# Samples ordered by response, genes ordered by deregulation direction
library(pheatmap)
save_pheatmap_tiff = function(x, filename, width = 174, height = 120.8333, res = 650,
                              units = "mm") {
  tiff(filename, width = width, height = height, res = res, units = units, 
       compression = "lzw")
  grid::grid.newpage()
  grid::grid.draw(x$gtable)
  dev.off()
}

save_pheatmap_tiff_poster = function(x, filename, width = 420, height = 291.66, res = 750,
                              units = "mm") {
  tiff(filename, width = width, height = height, res = res, units = units, 
       compression = "lzw")
  grid::grid.newpage()
  grid::grid.draw(x$gtable)
  dev.off()
}

annotation_for_heatmap = Pheno_exprs %>% dplyr::select(-Timepoint, -Patient.ID,
                                                       -Treatment_status, -Chemo_status,
                                                       -Endo_status, -Response_type, -Response_coded,
                                                       -Platform, -Platform_comp, -Mammaprint_score,
                                                       -rorS_score, -ClaudinLow, -nr) %>%
  dplyr::rename(Timepoint = Timepoint_coded) %>%
  inner_join(cluster_results, by = "Sample.ID") %>%
  dplyr::select(Cluster, Response, Timepoint, Treatment, Dataset, everything())
rownames(annotation_for_heatmap) = annotation_for_heatmap$Sample.ID
annotation_for_heatmap$Mammaprint_risk = factor(annotation_for_heatmap$Mammaprint_risk,
                                                levels = unique(annotation_for_heatmap$Mammaprint_risk),
                                                labels = c("Risk", "No risk"))
annotation_for_heatmap$Cluster = factor(annotation_for_heatmap$Cluster,
                                        levels = unique(annotation_for_heatmap$Cluster),
                                        labels = c("Cluster 2", "Cluster 1"))
annotation_for_heatmap$Timepoint = factor(annotation_for_heatmap$Timepoint,
                                          levels = unique(annotation_for_heatmap$Timepoint),
                                          labels = c("T1", "T2"))

# Samples ordered by response: Non-responders first
# response_ordered = annotation_for_heatmap[order(annotation_for_heatmap$Response, 
#                                                decreasing = TRUE), "Sample.ID"]

# Samples ordered by cluster: cluster 1 first
cluster_ordered = annotation_for_heatmap[order(annotation_for_heatmap$Cluster, 
                                                decreasing = TRUE), "Sample.ID"]
annotation_for_heatmap = annotation_for_heatmap %>% 
  dplyr::select(-Sample.ID)

# Genes ordered by logFC: Max positive -> 0 -> "Max" negative
genes_ordered = KBZ_DE_mapped[KBZ_DE_mapped$adj.P.Val<0.05,][order(KBZ_DE_mapped[KBZ_DE_mapped$adj.P.Val<0.05,]$logFC,
                                                                   decreasing = TRUE), c("EntrezGene.ID", "Gene.Symbol")]
plot_matrix = z_exprs[which(rownames(z_exprs) %in% genes_ordered$EntrezGene.ID), 
                      cluster_ordered]
check = as.data.frame(list(EntrezGene.ID = rownames(plot_matrix))) %>%
  inner_join(genes_ordered, by = "EntrezGene.ID")
rownames(plot_matrix) = check$Gene.Symbol
plot_matrix = plot_matrix[genes_ordered$Gene.Symbol,]

hmcol = rev(colorRampPalette(RColorBrewer::brewer.pal(9, "RdBu"))(255))

ann_colors = list(
  Response = c(Responder = "dodgerblue4", Non_responder = "deeppink4"),
  Dataset = c(C1 = "cyan", C2 = "orange", C3 = "red4", E1_1 = "darkseagreen",
              E1_2 = "beige", E1_3 = "blue4", E2 = "deeppink",
              E3 = "purple", E4_1 = "grey", E4_2 = "darkgreen"),
  Timepoint = c(T1 = "goldenrod2", T2 = "purple4"),#, T2.5 = "green", T3 = "blue"),
  Treatment = c(Chemotherapy = "paleturquoise3", Endocrine_treatment = "sienna2"),
  scmod1 = c(`ER-/HER2-` = "red4", `ER+/HER2- High Prolif` = "skyblue",
             `ER+/HER2- Low Prolif` = "darkblue", `HER2+` = "purple4"),
  pam50 = c(Basal = "red4", LumB = "skyblue",
            LumA = "darkblue", Her2 = "purple4", Normal = "lightgreen"),
  IC10 = c(iC1 = "pink3", iC2 = "red", iC3 = "red4", iC4 = "beige", iC5 = "aliceblue",
           iC6 = "cadetblue3", iC7 = "darkmagenta", iC8 = "hotpink4", iC9 = "lightpink2",
           iC10 = "mistyrose1"),
  rorS_risk = c(High = "red4", Intermediate = "orange", Low = "chartreuse4"),
  Mammaprint_risk = c(Risk = "red3", `No risk` = "green4"),
  Cluster = c(`Cluster 1` = "#68abb8",  `Cluster 2` = "#f2855d")
)

# Figure 3
heatmap = pheatmap(plot_matrix, col = (hmcol),
                   breaks = seq(-2, 2, 4/256),
                   annotation_col = annotation_for_heatmap,
                   annotation_colors = ann_colors,
                   cluster_cols = F,
                   cluster_rows = F,
                   gaps_row = 48,
                   gaps_col = 534,
                   treeheight_col =  0,
                   legend = TRUE,
                   show_rownames = T,
                   fontsize = 4,
                   fontsize_row = 2,
                   show_colnames = F,
                   legend_breaks = c(-2, # min(plot_matrix, na.rm = TRUE), 
                                     2), # max(plot_matrix, na.rm = TRUE)), 
                   legend_labels = (c("lower expression", "higher expression")))
save_pheatmap_tiff(heatmap, "data/Output sets/Downstream/NRS_genes_clusters_heatmap.tiff")
  
# Save for use in another script:
saveRDS(annotation_for_heatmap, "Signatures/annotation_for_heatmap.rds")
# saveRDS(mock, "Signatures/mock.rds")
saveRDS(plot_matrix, "Signatures/heatmap_plot_matrix.rds")
saveRDS(z_exprs, "Signatures/normalised_expression.rds")
saveRDS(z_design, "Signatures/design_matrix.rds")
saveRDS(z_cm, "Signatures/contrast_matrix.rds")

##### Plotly #####
library(plotly)
library(data.table)
library(colorspace)

Pheno_sunburst = annotation_for_heatmap %>% 
  dplyr::select(Cluster, Response, pam50, Mammaprint_risk)

Pheno_sunburst = Pheno_sunburst %>%
  group_by(Cluster, Response, pam50, Mammaprint_risk) %>%
  summarise(Counts = n()) %>%
  as.data.frame()

as.sunburstDF = function(DF, value_column = NULL, add_root = FALSE){
  require(data.table)
  
  colNamesDF = names(DF)
  
  if(is.data.table(DF)){
    DT = copy(DF)
  } else {
    DT = data.table(DF, stringsAsFactors = FALSE)
  }
  
  if(add_root){
    DT[, root := "Total"]  
  }
  
  colNamesDT = names(DT)
  hierarchy_columns = setdiff(colNamesDT, value_column)
  DT[, (hierarchy_columns) := lapply(.SD, as.factor), .SDcols = hierarchy_columns]
  
  if(is.null(value_column) && add_root){
    setcolorder(DT, c("root", colNamesDF))
  } else if(!is.null(value_column) && !add_root) {
    setnames(DT, value_column, "values", skip_absent=TRUE)
    setcolorder(DT, c(setdiff(colNamesDF, value_column), "values"))
  } else if(!is.null(value_column) && add_root) {
    setnames(DT, value_column, "values", skip_absent=TRUE)
    setcolorder(DT, c("root", setdiff(colNamesDF, value_column), "values"))
  }
  
  hierarchyList = list()
  
  for(i in seq_along(hierarchy_columns)){
    current_columns = colNamesDT[1:i]
    if(is.null(value_column)){
      currentDT = unique(DT[, ..current_columns][, values := .N, by = current_columns], by = current_columns)
    } else {
      currentDT = DT[, lapply(.SD, sum, na.rm = TRUE), by=current_columns, .SDcols = "values"]
    }
    setnames(currentDT, length(current_columns), "labels")
    hierarchyList[[i]] = currentDT
  }
  
  hierarchyDT = rbindlist(hierarchyList, use.names = TRUE, fill = TRUE)
  
  parent_columns = setdiff(names(hierarchyDT), c("labels", "values", value_column))
  hierarchyDT[, parents := apply(.SD, 1, function(x){fifelse(all(is.na(x)), yes = NA_character_, no = paste(x[!is.na(x)], sep = ":", collapse = " - "))}), .SDcols = parent_columns]
  hierarchyDT[, ids := apply(.SD, 1, function(x){paste(x[!is.na(x)], collapse = " - ")}), .SDcols = c("parents", "labels")]
  hierarchyDT[, c(parent_columns) := NULL]
  return(hierarchyDT)
}

coloring  = data.frame(stringsAsFactors = FALSE,
                       colors = tolower(gplots::col2hex(c("orange", "skyblue", "deeppink4", "dodgerblue4",
                                                          "red4", "violet", "darkblue", "skyblue", "lightgreen",
                                                          "#37023E", "#D8F351"))),
                       labels = c("Cluster 1", "Cluster 2", "Non_responder", "Responder",
                                  "Basal", "Her2", "LumA", "LumB", "Normal",
                                  "Risk", "No risk"))

sunburstDF = as.sunburstDF(Pheno_sunburst, value_column = "Counts", add_root = FALSE) %>%
  inner_join(coloring, by = "labels")

pie = plot_ly() %>%
  add_trace(ids = sunburstDF$ids, labels= sunburstDF$labels, parents = sunburstDF$parents, 
            values= sunburstDF$values, type='sunburst', branchvalues = 'total',
            insidetextorientation='radial', maxdepth = 5,
            marker = list(colors = sunburstDF$colors)) %>%
  layout(
    grid = list(columns =1, rows = 1),
    margin = list(l = 0, r = 0, b = 0, t = 0)
  )
pie

# Training, Validation, Test set splitting #####
# The sets are generated once and then filtered for variables of interest in
# the ML training, validating, testing process

KBZ_Entrez_list = KBZ_DE_mapped %>% dplyr::filter(adj.P.Val < 0.05) %>%
  dplyr::select(EntrezGene.ID, Gene.Symbol)
data = as.data.frame(t(z_exprs))
siggenes = intersect(colnames(data), KBZ_Entrez_list$EntrezGene.ID)
data = data %>% dplyr::select(all_of(siggenes))
data$Sample.ID = rownames(data)
train_set$Treatment = as.factor(train_set$Treatment)
train_set$Timepoint_coded = factor(train_set$Timepoint_coded, 
                                   levels = unique(train_set$Timepoint_coded),
                                   labels = c("T1", "T2"))
train_set = train_set %>%
  inner_join(data, by = "Sample.ID") %>%
  inner_join(cluster_results, by = "Sample.ID") %>%
  inner_join(Pheno_exprs %>% dplyr::select(Sample.ID, pam50, rorS_risk, scmod1, IC10,
                                           Mammaprint_risk), by = "Sample.ID") %>%
  dplyr::select(-Patient.ID, -Treatment_status, -Chemo_status, -Endo_status, -Response_type,
                -Response_coded, -Timepoint, -Platform, -Platform_comp)
str_sub(colnames(train_set)[16:181],0,0) = "X_"

# Repeat for validation set
validation_set$Treatment = as.factor(validation_set$Treatment)
validation_set$Timepoint_coded = factor(validation_set$Timepoint_coded, 
                                        levels = unique(validation_set$Timepoint_coded),
                                        labels = c("T1", "T2"))
validation_set = validation_set %>%
  inner_join(data, by = "Sample.ID") %>%
  inner_join(cluster_results, by = "Sample.ID") %>%
  inner_join(Pheno_exprs %>% dplyr::select(Sample.ID, pam50, rorS_risk, scmod1, IC10,
                                           Mammaprint_risk), by = "Sample.ID") %>%
  dplyr::select(-Patient.ID, -Treatment_status, -Chemo_status, -Endo_status, -Response_type,
                -Response_coded, -Timepoint, -Platform, -Platform_comp)
str_sub(colnames(validation_set)[16:181],0,0) = "X_"


train_set$Cluster = as.factor(train_set$Cluster); validation_set$Cluster = as.factor(validation_set$Cluster)
# Lists of training and validation sets:
# Training
train_gs = train_set %>% 
  dplyr::select(-nr, -pam50, -Sample.ID, -Timepoint_coded, -Treatment,
                -Dataset, -Cluster, -rorS_risk, -scmod1, -IC10,
                -Mammaprint_risk)
unchanged = colnames(train_gs)

train_meta = train_set %>% 
  dplyr::select(Response, pam50, Timepoint_coded, Treatment, IC10,
                Mammaprint_risk, rorS_risk, scmod1)
train_meta = cbind(train_meta[,"Response"], as.data.frame(model.matrix(~0 + train_meta$pam50 +
                                                                         train_meta$Timepoint_coded +
                                                                         train_meta$Treatment +
                                                                         train_meta$IC10 +
                                                                         train_meta$Mammaprint_risk +
                                                                         train_meta$rorS_risk +
                                                                         train_meta$scmod1)))
colnames(train_meta) = c("Response", "Basal", "HER2", "LumB", "LumA",
                                 "Normal", "T2", "Endo", "IC2", "IC3", "IC4",
                                 "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                                 "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")
train_meta = train_meta %>% dplyr::select(-Basal)
train_meta[colnames(train_meta[,2:ncol(train_meta)])] = 
  lapply(train_meta[colnames(train_meta[,2:ncol(train_meta)])], 
         function(x) factor(x, levels = c(0,1), labels = c(0,1)))

train_cluster_meta = train_set %>% 
  dplyr::select(Response, pam50, Timepoint_coded, Treatment, Cluster, IC10,
                Mammaprint_risk, rorS_risk, scmod1)
train_cluster_meta = cbind(train_cluster_meta[,"Response"], as.data.frame(model.matrix(~0 + train_cluster_meta$pam50 +
                                                                                         train_cluster_meta$Timepoint_coded +
                                                                                         train_cluster_meta$Treatment +
                                                                                         train_cluster_meta$Cluster +
                                                                                         train_cluster_meta$IC10 +
                                                                                         train_cluster_meta$Mammaprint_risk +
                                                                                         train_cluster_meta$rorS_risk +
                                                                                         train_cluster_meta$scmod1)))
colnames(train_cluster_meta) = c("Response", "Basal", "HER2", "LumB", "LumA",
                                 "Normal", "T2", "Endo", "Cluster_2", "IC2", "IC3", "IC4",
                                 "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                                 "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")
train_cluster_meta = train_cluster_meta %>% dplyr::select(-Basal)
train_cluster_meta[colnames(train_cluster_meta[,2:ncol(train_cluster_meta)])] = 
  lapply(train_cluster_meta[colnames(train_cluster_meta[,2:ncol(train_cluster_meta)])], 
         function(x) factor(x, levels = c(0,1), labels = c(0,1)))

train_gs_meta = train_set %>% 
  dplyr::select(-nr, -Sample.ID, -Cluster)
train_gs_meta = cbind(train_gs_meta[,unchanged], as.data.frame(model.matrix(~0 + train_gs_meta$pam50 +
                                                                              train_gs_meta$Timepoint_coded +
                                                                              train_gs_meta$Treatment +
                                                                              train_gs_meta$IC10 +
                                                                              train_gs_meta$Mammaprint_risk +
                                                                              train_gs_meta$rorS_risk +
                                                                              train_gs_meta$scmod1)))
colnames(train_gs_meta) = c(unchanged, "Basal", "HER2", "LumB", "LumA",
                            "Normal", "T2", "Endo", "IC2", "IC3", "IC4",
                            "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                            "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")
train_gs_meta = train_gs_meta %>% dplyr::select(-Basal)
train_gs_meta[c("HER2", "LumB", "LumA",
                "Normal", "T2", "Endo", "IC2", "IC3", "IC4",
                "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")] = 
  lapply(train_gs_meta[c("HER2", "LumB", "LumA", "Normal", "T2", "Endo",
                         "IC2", "IC3", "IC4",
                         "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                         "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")],
         function(x) factor(x, levels = c(0,1), 
                            labels = c(0,1)))

train_all = train_set %>% 
  dplyr::select(-nr, -Sample.ID)
train_all = cbind(train_all[,unchanged], 
                  as.data.frame(model.matrix(~0 + train_all$pam50 +
                                               train_all$Timepoint_coded +
                                               train_all$Treatment +
                                               train_all$Cluster +
                                               train_all$IC10 +
                                               train_all$Mammaprint_risk +
                                               train_all$rorS_risk +
                                               train_all$scmod1)))

colnames(train_all) = c(unchanged, "Basal", "HER2", "LumB", "LumA",
                        "Normal", "T2", "Endo", "Cluster_2", "IC2", "IC3", "IC4",
                        "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                        "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")
train_all = train_all %>% dplyr::select(-Basal)
train_all[c("HER2", "LumB", "LumA",
            "Normal", "T2", "Endo", "Cluster_2", "IC2", "IC3", "IC4",
            "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
            "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")] = 
  lapply(train_all[c("HER2", "LumB", "LumA", "Normal", "T2", "Endo",
                     "Cluster_2", "IC2", "IC3", "IC4",
                     "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                     "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")],
         function(x) factor(x, levels = c(0,1), 
                            labels = c(0,1)))

Training = list(train_gs, train_meta, train_cluster_meta, train_gs_meta, train_all)
names(Training) = c("GS", "meta", "Cluster_meta", "GS_meta", "All_together")
rm(train_gs, train_meta, train_cluster_meta, train_gs_meta, train_all)

# Validation
validation_gs = validation_set %>% 
  dplyr::select(-nr, -pam50, -Sample.ID, -Timepoint_coded, -Treatment,
                -Dataset, -Cluster, -rorS_risk, -scmod1, -IC10,
                -Mammaprint_risk)
unchanged = colnames(validation_gs)

validation_meta = validation_set %>% 
  dplyr::select(Response, pam50, Timepoint_coded, Treatment, IC10,
                Mammaprint_risk, rorS_risk, scmod1)
validation_meta = cbind(validation_meta[,"Response"], as.data.frame(model.matrix(~0 + validation_meta$pam50 +
                                                                                   validation_meta$Timepoint_coded +
                                                                                   validation_meta$Treatment +
                                                                                   validation_meta$IC10 +
                                                                                   validation_meta$Mammaprint_risk +
                                                                                   validation_meta$rorS_risk +
                                                                                   validation_meta$scmod1)))
colnames(validation_meta) = c("Response", "Basal", "HER2", "LumB", "LumA",
                              "Normal", "T2", "Endo", "IC2", "IC3", "IC4",
                              "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                              "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")
validation_meta = validation_meta %>% dplyr::select(-Basal)
validation_meta[colnames(validation_meta[,2:ncol(validation_meta)])] = 
  lapply(validation_meta[colnames(validation_meta[,2:ncol(validation_meta)])], 
         function(x) factor(x, levels = c(0,1), labels = c(0,1)))

validation_cluster_meta = validation_set %>% 
  dplyr::select(Response, pam50, Timepoint_coded, Treatment, Cluster, IC10,
                Mammaprint_risk, rorS_risk, scmod1)
validation_cluster_meta = cbind(validation_cluster_meta[,"Response"], 
                                as.data.frame(model.matrix(~0 +
                                                             validation_cluster_meta$pam50 +
                                                             validation_cluster_meta$Timepoint_coded +
                                                             validation_cluster_meta$Treatment +
                                                             validation_cluster_meta$Cluster +
                                                             validation_cluster_meta$IC10 +
                                                             validation_cluster_meta$Mammaprint_risk +
                                                             validation_cluster_meta$rorS_risk +
                                                             validation_cluster_meta$scmod1)))
colnames(validation_cluster_meta) = c("Response", "Basal", "HER2", "LumB", "LumA",
                                      "Normal", "T2", "Endo", "Cluster_2", "IC2", "IC3", "IC4",
                                      "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                                      "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")
validation_cluster_meta = validation_cluster_meta %>% dplyr::select(-Basal)
validation_cluster_meta[colnames(validation_cluster_meta[,2:ncol(validation_cluster_meta)])] = 
  lapply(validation_cluster_meta[colnames(validation_cluster_meta[,2:ncol(validation_cluster_meta)])], 
         function(x) factor(x, levels = c(0,1), labels = c(0,1)))

validation_gs_meta = validation_set %>% 
  dplyr::select(-nr, -Sample.ID, -Cluster)
validation_gs_meta = cbind(validation_gs_meta[,unchanged], as.data.frame(model.matrix(~0 + validation_gs_meta$pam50 +
                                                                                        validation_gs_meta$Timepoint_coded +
                                                                                        validation_gs_meta$Treatment +
                                                                                        validation_gs_meta$IC10 +
                                                                                        validation_gs_meta$Mammaprint_risk +
                                                                                        validation_gs_meta$rorS_risk +
                                                                                        validation_gs_meta$scmod1)))
colnames(validation_gs_meta) = c(unchanged, "Basal", "HER2", "LumB", "LumA",
                                 "Normal", "T2", "Endo", "IC2", "IC3", "IC4",
                                 "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                                 "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")
validation_gs_meta = validation_gs_meta %>% dplyr::select(-Basal)
validation_gs_meta[c("HER2", "LumB", "LumA",
                     "Normal", "T2", "Endo", "IC2", "IC3", "IC4",
                     "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                     "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")] = 
  lapply(validation_gs_meta[c("HER2", "LumB", "LumA", "Normal", "T2", "Endo",
                              "IC2", "IC3", "IC4",
                              "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                              "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")],
         function(x) factor(x, levels = c(0,1), 
                            labels = c(0,1)))

validation_all = validation_set %>% 
  dplyr::select(-nr, -Sample.ID)
validation_all = cbind(validation_all[,unchanged], 
                       as.data.frame(model.matrix(~0 + validation_all$pam50 +
                                                    validation_all$Timepoint_coded +
                                                    validation_all$Treatment +
                                                    validation_all$Cluster +
                                                    validation_all$IC10 +
                                                    validation_all$Mammaprint_risk +
                                                    validation_all$rorS_risk +
                                                    validation_all$scmod1)))

colnames(validation_all) = c(unchanged, "Basal", "HER2", "LumB", "LumA",
                             "Normal", "T2", "Endo", "Cluster_2", "IC2", "IC3", "IC4",
                             "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                             "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")
validation_all = validation_all %>% dplyr::select(-Basal)
validation_all[c("HER2", "LumB", "LumA",
                 "Normal", "T2", "Endo", "Cluster_2", "IC2", "IC3", "IC4",
                 "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                 "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")] = 
  lapply(validation_all[c("HER2", "LumB", "LumA", "Normal", "T2", "Endo",
                          "Cluster_2", "IC2", "IC3", "IC4",
                          "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                          "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")],
         function(x) factor(x, levels = c(0,1), 
                            labels = c(0,1)))

Validation = list(validation_gs, validation_meta, validation_cluster_meta,
                  validation_gs_meta, validation_all)
names(Validation) = c("GS", "meta", "Cluster_meta", "GS_meta", "All_together")
rm(validation_gs, validation_meta, validation_cluster_meta, validation_gs_meta, validation_all)

# Logistic Regression: backward and lasso-regularised models #####

# Preparing output
logrwb = createWorkbook()
LogR_models_back = list()
LogR_models_reg  = list()

# Model tuning and building
trControl = trainControl(method = "repeatedcv",
                         repeats = 10,
                         number = 10, allowParallel = TRUE)

for(i in 1:length(Training)){
  LogR_accuracy = data.frame(matrix(ncol=3,0))
  colnames(LogR_accuracy) = c("Method", "Accuracy_train", "Accuracy_validation")
  
  RNGversion("4.0.2")
  set.seed(123)
  LogR_model_back = train(Response ~., 
                          data = Training[[i]], 
                          method = "glmStepAIC", 
                          family = "binomial",
                          trControl = trControl,
                          na.action = "na.omit",
                          direction = "backward")
  
  train_pred = predict(LogR_model_back, Training[[i]])
  agree_train = ifelse(train_pred == Training[[i]]$Response, 1, 0)
  accuracy_train = sum(agree_train) / nrow(Training[[i]])
  
  validation_pred = predict(LogR_model_back, Validation[[i]])
  agree_validation = ifelse(validation_pred == Validation[[i]]$Response, 1, 0)
  accuracy_validation = sum(agree_validation) / nrow(Validation[[i]])
  
  LogR_models_back[[i]] = LogR_model_back
  LogR_accuracy = rbind(LogR_accuracy, c("Backward LogR", accuracy_train, accuracy_validation))
  rm(train_pred, agree_train, accuracy_train, validation_pred, 
     agree_validation, accuracy_validation)
  
  RNGversion("4.0.2")
  set.seed(123)
  LogR_model_reg = train(Response ~., 
                         data = Training[[i]], 
                         method = "glmnet", 
                         family = "binomial",
                         trControl = trControl,
                         na.action = "na.omit")
  
  train_pred = predict(LogR_model_reg, Training[[i]])
  agree_train = ifelse(train_pred == Training[[i]]$Response, 1, 0)
  accuracy_train = sum(agree_train) / nrow(Training[[i]])
  
  validation_pred = predict(LogR_model_reg, Validation[[i]])
  agree_validation = ifelse(validation_pred == Validation[[i]]$Response, 1, 0)
  accuracy_validation = sum(agree_validation) / nrow(Validation[[i]])
  
  LogR_models_reg[[i]] = LogR_model_reg
  LogR_accuracy = rbind(LogR_accuracy, c("Regularised LogR", accuracy_train, accuracy_validation))
  LogR_accuracy = LogR_accuracy[2:nrow(LogR_accuracy),]
  
  addWorksheet(logrwb, names(Training)[i])
  writeData(logrwb, names(Training)[i], LogR_accuracy)
  
  rm(train_pred, agree_train, accuracy_train, validation_pred, 
     agree_validation, accuracy_validation, LogR_model_reg, LogR_model_back)
}

saveWorkbook(logrwb, file = "data/Output sets/Downstream/LogR.xlsx",
             overwrite = TRUE); rm(logrwb, trControl)

names(LogR_models_reg) = names(Training)
names(LogR_models_back) = names(Training)
LogR = list(LogR_models_reg, LogR_models_back)
names(LogR) = c("Regularised models", "Backward models")
rm(LogR_models_back, LogR_models_reg)

# Decision trees #####
if(length(KBZ_DE_mapped$EntrezGene.ID[KBZ_DE_mapped$adj.P.Val < 0.05])>0){
  
  # Preparing output
  grid1 = expand.grid(model = c("tree", "rule"),
                      trials = c(10,15,25,50,100),
                      winnow = c(TRUE, FALSE))
  ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 10,
                      selectionFunction = "best", allowParallel = TRUE)
  grid_c50 = expand.grid(model = c("tree", "rule"),
                         trials = c(10,15,25,50,100),
                         winnow = c(TRUE, FALSE))
  ctrls = trainControl(method = "repeatedcv", number = 10, repeats = 10,
                       selectionFunction = "best", savePredictions = TRUE,
                       classProbs = TRUE, summaryFunction = twoClassSummary,
                       allowParallel = TRUE)
  grid2 = expand.grid(mtry=c(2, 4, 7, 10, 12, 15, 17, 20, 23, 25, 
                             30, 40, 50, 75, 100, 125, 150, 170))
  dtwb = createWorkbook()
  DT = list()
  
  for (i in 1:length(Training)) {
    DT_Accuracy = data.frame(matrix(ncol=3,0))
    colnames(DT_Accuracy) = c("Model", "Accuracy_train", "Accuracy_validation")
    
    # C5.0 - k
    RNGversion("4.0.2")
    set.seed(123)
    C50_model = train(Response ~., data = Training[[i]],
                      method = "C5.0",
                      trControl = ctrl,
                      metric = "Kappa",
                      tuneGrid = grid1,
                      na.action = "na.omit")
    
    model_preds_validation = predict(C50_model, Validation[[i]])
    model_table_validation = table(model_preds_validation, Validation[[i]]$Response)
    model_accuracy_validation = (model_table_validation[1] + model_table_validation[4])/
      sum(model_table_validation)
    
    DT_Accuracy = rbind(DT_Accuracy, c("C5.0 - k", max(C50_model$results$Accuracy),
                                       model_accuracy_validation))
    
    rm(model_preds_validation, model_table_validation, model_accuracy_validation)
    
    # Bagging
    RNGversion("4.0.2")
    set.seed(123)
    model_bag = bagging(Response ~., data = Training[[i]],
                        nbagg = 100)
    
    bag_pred_train = predict(model_bag, Training[[i]])
    bag_train_t = table(bag_pred_train$class, Training[[i]]$Response)
    bagging_train_accuracy = 1 - (bag_train_t[1] + bag_train_t[4])/
      sum(bag_train_t)
    
    bag_pred_validation = predict(model_bag, Validation[[i]])
    bag_validation_t = table(bag_pred_validation$class, Validation[[i]]$Response)
    bagging_accuracy_validation = 1 - (bag_validation_t[1] + bag_validation_t[4])/
      sum(bag_validation_t)
    
    DT_Accuracy = rbind(DT_Accuracy, c("100X Bagging", bagging_train_accuracy, 
                                       bagging_accuracy_validation))
    
    rm(bag_pred_train, bag_train_t, bagging_train_accuracy,
       bag_pred_validation, bag_validation_t, bagging_accuracy_validation)
    
    # Boosting
    RNGversion("4.0.2")
    set.seed(123)
    boost = boosting(Response ~., data = Training[[i]])
    
    boost_train_pred = predict(boost, Training[[i]])
    cm_boost_train = boost_train_pred$confusion
    boost_accuracy_train = 1 - (cm_boost_train[1] + cm_boost_train[4])/
      sum(cm_boost_train)
    
    boost_validation_pred = predict(boost, Validation[[i]])
    cm_boost_validation = boost_validation_pred$confusion
    boost_accuracy_validation = 1 - (cm_boost_validation[1] + cm_boost_validation[4])/
      sum(cm_boost_validation)
    
    DT_Accuracy = rbind(DT_Accuracy, c("Boosting", boost_accuracy_train,
                                       boost_accuracy_validation))
    
    rm(boost_train_pred, cm_boost_train, boost_accuracy_train,
       boost_validation_pred, cm_boost_validation, boost_accuracy_validation)
    
    # Boosting with cross-validation on the whole dataset
    # train
    RNGversion("4.0.2")
    set.seed(123)
    adaboost_cv = boosting.cv(Response ~., data = cbind(rbind(Training[[i]],
                                                              Validation[[i]])),
                              mfinal = 100)
    
    cm_adaboost = adaboost_cv$confusion
    adaboost_accuracy = 1 - (cm_adaboost[1] + cm_adaboost[4])/sum(cm_adaboost)
    
    DT_Accuracy = rbind(DT_Accuracy, c("Adaboost", adaboost_accuracy, adaboost_accuracy))
    
    rm(cm_adaboost, adaboost_accuracy)
    
    # Random Forest
    RNGversion("4.0.2")
    set.seed(123)
    rf = train(Response ~., data = Training[[i]],
               method = "rf",
               metric = "Kappa", trControl = ctrl, tuneGrid = grid2,
               na.action = "na.omit")
    
    rf_preds_validation = predict(rf, Validation[[i]])
    rf_table_validation = table(rf_preds_validation, Validation[[i]]$Response)
    rf_validation_accuracy = (rf_table_validation[1] + rf_table_validation[4])/
      sum(rf_table_validation)
    
    DT_Accuracy = rbind(DT_Accuracy, c("Random Forest - k", max(rf$results$Accuracy),
                                       rf_validation_accuracy))
    
    rm(rf_preds_validation, rf_table_validation, rf_validation_accuracy)
    
    # RF with grid2 and ctrls, ROC
    RNGversion("4.0.2")
    set.seed(123)
    comp_rf = train(Response ~., data = Training[[i]],
                    method = "rf",
                    metric = "ROC", trControl = ctrls, tuneGrid = grid2,
                    na.action = "na.omit")
    
    comp_rf_preds_validation = predict(comp_rf, Validation[[i]])
    comp_rf_table_validation = table(comp_rf_preds_validation, Validation[[i]]$Response)
    comp_rf_accuracy_validation = (comp_rf_table_validation[1] + comp_rf_table_validation[4])/
      sum(comp_rf_table_validation)
    
    DT_Accuracy = rbind(DT_Accuracy, c("Random Forest - ROC", max(comp_rf$results$ROC),
                                       comp_rf_accuracy_validation))
    
    rm(comp_rf_preds_validation, comp_rf_table_validation, comp_rf_accuracy_validation)
    
    # C5.0 with grid_c50
    RNGversion("4.0.2")
    set.seed(123)
    m_c50 = train(Response ~., data = Training[[i]],
                  method="C5.0", metric = "ROC",
                  trControl = ctrls, tuneGrid = grid_c50, 
                  na.action = "na.omit")
    
    m_c50_preds_validation = predict(m_c50, Validation[[i]])
    m_c50_table_validation = table(m_c50_preds_validation, Validation[[i]]$Response)
    m_c50_accuracy_validation = (m_c50_table_validation[1] + m_c50_table_validation[4])/
      sum(m_c50_table_validation)
    
    DT_Accuracy = rbind(DT_Accuracy, c("C5.0 - ROC", max(m_c50$results$ROC),
                                       m_c50_accuracy_validation))
    
    rm(m_c50_preds_validation, m_c50_table_validation, m_c50_accuracy_validation)
    
    # Finalising
    DT_models = list(C50_model, model_bag, boost, adaboost_cv, 
                     rf, comp_rf, m_c50)
    names(DT_models) = c("C5.0 - k", "100X Bagging", "Boosting", "Boosting.cv",
                         "RForest - k", "RForest - ROC", 
                         "C5.0 - ROC")
    DT[[i]] = DT_models
    DT_Accuracy = DT_Accuracy[2:nrow(DT_Accuracy),]
    addWorksheet(dtwb, names(Training)[i])
    writeData(dtwb, names(Training)[i], DT_Accuracy)
    rm(C50_model, model_bag, boost, adaboost_cv, rf, comp_rf, m_c50, 
       DT_Accuracy, DT_models) 
    gc()
    cat(paste0("Done with ", names(Training)[i], "\n"))
  }
  
  saveWorkbook(dtwb, file = "data/Output sets/Downstream/DT.xlsx",
               overwrite = TRUE) 
  rm(dtwb)
  names(DT) = names(Training)
}

# SVMs #####
if(length(KBZ_DE_mapped$EntrezGene.ID[KBZ_DE_mapped$adj.P.Val < 0.05])>0){
  
  # Preparing output
  SVM = list()
  svmwb = createWorkbook()
  cost_values = seq(from = 0.5, to = 20, by = 0.5)
  linear_svm_ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 10,
                                 selectionFunction = "best", allowParallel = TRUE)
  linear_svm_tune = expand.grid(C = cost_values)
  L2_linear_svm_ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 10,
                                    selectionFunction = "best", allowParallel = TRUE)
  L2_linear_svm_tune = expand.grid(cost = cost_values,
                                   Loss = "L2")
  rbf_svm_ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 10,
                              selectionFunction = "best", allowParallel = TRUE)
  rbf_svm_tune = expand.grid(C = cost_values,
                             sigma = c(0, 0.02, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9))
  
  for(i in 1:length(Training)){
    SVM_Accuracy = data.frame(matrix(ncol=5,0))
    colnames(SVM_Accuracy) = c("Kernel", "Cost_value_C", "Sigma", 
                               "Accuracy_train", "Accuracy_validation")
    
    # Linear kernel - simple
    RNGversion("4.0.2")
    set.seed(123)
    linear_svm_model = train(Response ~., data = Training[[i]], 
                             method = "svmLinear", 
                             preProcess = NULL,
                             trControl = linear_svm_ctrl,
                             tuneGrid = linear_svm_tune,
                             na.action = "na.omit")
    
    train_pred = predict(linear_svm_model, Training[[i]])
    agree_train = ifelse(train_pred == Training[[i]]$Response, 1, 0)
    accuracy_train = sum(agree_train) / nrow(Training[[i]])
    
    validation_pred = predict(linear_svm_model, Validation[[i]])
    agree_validation = ifelse(validation_pred == Validation[[i]]$Response, 1, 0)
    accuracy_validation = sum(agree_validation) / nrow(Validation[[i]])
    
    SVM_Accuracy = rbind(SVM_Accuracy, c("Linear", linear_svm_model$bestTune[["C"]], "NA",
                                         accuracy_train, accuracy_validation))
    
    rm(train_pred, agree_train, accuracy_train, validation_pred, agree_validation,
       accuracy_validation)
    
    # Linear kernel - L2 regularised
    RNGversion("4.0.2")
    set.seed(123)
    L2_linear_svm_model = train(Response ~., data = Training[[i]], 
                                method = "svmLinear3", 
                                preProcess = NULL,
                                trControl = L2_linear_svm_ctrl,
                                tuneGrid = L2_linear_svm_tune,
                                na.action = "na.omit")
    
    train_pred = predict(L2_linear_svm_model, Training[[i]])
    agree_train = ifelse(train_pred == Training[[i]]$Response, 1, 0)
    accuracy_train = sum(agree_train) / nrow(Training[[i]])
    
    validation_pred = predict(L2_linear_svm_model, Validation[[i]])
    agree_validation = ifelse(validation_pred == Validation[[i]]$Response, 1, 0)
    accuracy_validation = sum(agree_validation) / nrow(Validation[[i]])
    
    SVM_Accuracy = rbind(SVM_Accuracy, c("L2_Linear", L2_linear_svm_model$bestTune[["cost"]], 
                                         "NA", accuracy_train, accuracy_validation))
    
    rm(train_pred, agree_train, accuracy_train, validation_pred, agree_validation,
       accuracy_validation)
    
    # Radial Basis Function
    RNGversion("4.0.2")
    set.seed(123)
    rbf_svm_model = train(Response ~., data = Training[[i]], 
                          method = "svmRadial", 
                          preProcess = NULL,
                          trControl = rbf_svm_ctrl,
                          tuneGrid = rbf_svm_tune,
                          na.action = "na.omit")
    
    
    train_pred = predict(rbf_svm_model, Training[[i]])
    agree_train = ifelse(train_pred == Training[[i]]$Response, 1, 0)
    accuracy_train = sum(agree_train) / nrow(Training[[i]])
    
    validation_pred = predict(rbf_svm_model, Validation[[i]])
    agree_validation = ifelse(validation_pred == Validation[[i]]$Response, 1, 0)
    accuracy_validation = sum(agree_validation) / nrow(Validation[[i]])
    
    SVM_Accuracy = rbind(SVM_Accuracy, c("RBF", rbf_svm_model$bestTune[["C"]], 
                                         rbf_svm_model$bestTune[["sigma"]],
                                         accuracy_train, accuracy_validation))
    
    rm(train_pred, agree_train, accuracy_train, validation_pred, agree_validation,
       accuracy_validation)
    
    # Saving
    SVM_Accuracy = SVM_Accuracy[2:nrow(SVM_Accuracy),]
    SVM_models = list(linear_svm_model, L2_linear_svm_model, rbf_svm_model)
    names(SVM_models) = c("Linear", "L2 Linear", "RBF")
    SVM[[i]] = SVM_models
    addWorksheet(svmwb, names(Training)[i])
    writeData(svmwb, names(Training)[i], SVM_Accuracy)
    rm(linear_svm_model, L2_linear_svm_model,
       rbf_svm_model, SVM_Accuracy, SVM_models); gc()
    cat(paste0("Done with ", names(Training)[i], "\n"))
  }
  
  saveWorkbook(svmwb, file = "data/Output sets/Downstream/SVM.xlsx",
               overwrite = TRUE); rm(svmwb)
  names(SVM) = names(Training)
}

# Test set and external validation set #####

# According to the output .xlsx files, there is a 7-model tie, in terms of validation set
# classification accuracy ("data/Output sets/Downstream/Validation_performance.xlsx")
# Plotting ROC curves to choose a model visually (not applicable to SVM). The SVM model
# is left out because it doesn't take treatment into account.

Best_models = list(RF_k_cluster_meta = DT[["Cluster_meta"]][["RForest - k"]],
                   RF_ROC_cluster_meta = DT[["Cluster_meta"]][["RForest - ROC"]],
                   C5_ROC_cluster_meta = DT[["Cluster_meta"]][["C5.0 - ROC"]],
                   C5_k_gs_meta = DT[["GS_meta"]][["C5.0 - k"]],
                   C5_ROC_gs_meta = DT[["GS_meta"]][["C5.0 - ROC"]],
                   C5_ROC_all_together = DT[["All_together"]][["C5.0 - ROC"]])

AUC_values = list()
for (i in 1:length(Best_models)){
  model = Best_models[[i]]
  preds1 = predict(model, Validation[["All_together"]])
  preds = predict(model, Validation[["All_together"]], type = "prob")
  join = cbind(preds1, preds, Validation[["All_together"]])
  join = join[order(join$preds),]
  model_roc = roc(predictor = join$Responder, response = as.character(join$Response))
  AUC_values[[i]] = round(auc(model_roc), 3)
  tiff(paste0("data/Output sets/Downstream/Validation_ROC_plots/", names(Best_models)[i],
       ".tiff"), width = 1920, height = 1920, res = 700, compression = "lzw")
  par(mar = c(5, 5, 5, 5))
  par(oma = c(0.5, 0.5, 0.5, 0.5))
  plot(model_roc, 
       col = "blue", lwd = 2, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), asp = 1,
       cex.lab = 0.6, cex.axis = 0.7, xaxs = "i", yaxs = "i",
       xlab = substitute(paste(bold('1 - Specificity'))),
       ylab = substitute(paste(bold('Sensitivity'))))
  title(main = paste0("ROC curve for ", names(Best_models)[i], " classifier, AUC = ",
                      round(auc(model_roc), 3)),
        outer = TRUE, cex.main = 0.5, line = -1, adj = 0.8)
  dev.off()
  rm(model, preds1, preds, join, model_roc)
}

# Other error metrics
Metrics = as.data.frame(matrix(nrow = 1, ncol = 8))
colnames(Metrics) = c("Algorithm", "AUC", "Accuracy", "Precision", "Recall",
                      "FPR", "FNR", "F1")
for (i in 1:length(Best_models)){
  preds = predict(Best_models[[i]], Validation[["All_together"]])
  confusion = table(preds, Validation[["All_together"]]$Response)
  Metrics = rbind(Metrics, c(names(Best_models)[i], AUC_values[[i]], 
                             get_err_metric(confusion)))
}
Metrics = Metrics[-1,]

# Based on the ROC plots, the validation accuracy and the rest of the error metrics
# we decided that our final model will be the C5-ROC model with the gs_meta set 
# of predictors.

# We save the variable importance in an object
varImportance = varImp(Best_models[["C5_ROC_gs_meta"]])$importance
write.xlsx(cbind(rownames(varImportance), varImportance),
           "data/Output sets/Downstream/Variable_Importance.xlsx")

# Import the clean data frame
f = read.xlsx("data/Output sets/Downstream/Variable_Importance.xlsx", sheet = 2)
x_order = f$Variables

# Defining a legend alignment function
library(cowplot)
align_legend = function(p, hjust = 0.5)
{
  # extract legend
  g = cowplot::plot_to_gtable(p)
  grobs = g$grobs
  legend_index = which(sapply(grobs, function(x) x$name) == "guide-box")
  legend = grobs[[legend_index]]
  
  # extract guides table
  guides_index = which(sapply(legend$grobs, function(x) x$name) == "layout")
  
  # there can be multiple guides within one legend box  
  for (gi in guides_index) {
    guides = legend$grobs[[gi]]
    
    # add extra column for spacing
    # guides$width[5] is the extra spacing from the end of the legend text
    # to the end of the legend title. If we instead distribute it by `hjust:(1-hjust)` on
    # both sides, we get an aligned legend
    spacing = guides$width[5]
    guides = gtable::gtable_add_cols(guides, hjust*spacing, 1)
    guides$widths[6] = (1-hjust)*spacing
    title_index = guides$layout$name == "title"
    guides$layout$l[title_index] = 2
    
    # reconstruct guides and write back
    legend$grobs[[gi]] = guides
  }
  
  # reconstruct legend and write back
  g$grobs[[legend_index]] = legend
  g
}


# horizontal
varImp_plot = ggplot(f, aes(factor(Variables, levels = x_order,
                                   labels = x_order), Importance, color = Importance)) +
  geom_point(size = 0.05)+
  scale_color_distiller(palette = "RdBu")+
  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 10))+
  theme(plot.title = element_text(size = 4, face = "bold", vjust = 0.5),
        plot.subtitle = element_text(size = 3, vjust = 0.5),
        axis.text.x = element_text(size = 1.5, angle = 90, hjust = 1, vjust = 0.5, 
                                   color = "black", margin = ggplot2::margin(0, 0, 0, 0)),
        axis.text.y = element_text(size = 3),
        axis.title = element_text(size = 3, face = "bold"),
        axis.ticks = element_line(linewidth = 0.1),
        panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid.major = element_line(color = "grey95",
                                        linewidth = 0.1,
                                        linetype = 1),
        axis.line = element_line(linewidth = 0.2),
        legend.position = "right",
        legend.key.size = unit(1, units = "mm"),
        legend.text = element_text(size = 2),
        legend.title = element_text(face = "bold", size = 2),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"),
        legend.spacing.x = unit(0.5, units = "mm"),
        legend.background = element_blank()) +
  labs(title = "Variable Importance Scatter Plot",
       subtitle = bquote(italic("Final C5.0 ROC model")),
       x = "Variables",
       color = "Importance")
varImp_plot
ggdraw(align_legend(varImp_plot))
ggsave(filename = "Final_model_variable_importance.tiff",
       path = "data/Output sets/Downstream", 
       width = 2880, height = 1080, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

# vertical
varImp_plot_v = ggplot(f, aes(Importance, factor(Variables, levels = rev(x_order),
                                   labels = rev(x_order)), color = Importance)) +
  geom_point(size = 0.05)+
  scale_color_distiller(palette = "RdBu")+
  scale_x_continuous(limits = c(0, 100), breaks = seq(0, 100, 10))+
  theme(plot.title = element_text(size = 6, face = "bold", vjust = 0.5),
        plot.subtitle = element_text(size = 4, vjust = 0.5),
        axis.text.y = element_text(size = 1.5, hjust = 1, vjust = 0.5, 
                                   color = "black", margin = ggplot2::margin(0, 0, 0, 0)),
        axis.text.x = element_text(size = 4),
        axis.title = element_text(size = 5, face = "bold"),
        axis.ticks = element_line(linewidth = 0.1),
        panel.background = element_rect(fill = "white", 
                                        colour = "white"),
        panel.grid.major = element_line(color = "grey95",
                                        linewidth = 0.1,
                                        linetype = 1),
        axis.line = element_line(linewidth = 0.2),
        legend.position = "right",
        legend.key.size = unit(2, units = "mm"),
        legend.text = element_text(size = 3),
        legend.title = element_text(face = "bold", size = 3.5),
        legend.margin = ggplot2::margin(0, 0, 0, 0, unit = "mm"),
        legend.spacing.y = unit(0.5, units = "mm"),
        legend.spacing.x = unit(0.5, units = "mm"),
        legend.background = element_blank()) +
  labs(title = "Variable Importance Scatter Plot",
       subtitle = bquote(italic("Final C5.0 ROC model")),
       y = "Variables",
       color = "Importance")
varImp_plot_v
ggdraw(align_legend(varImp_plot_v))
ggsave(filename = "Final_model_variable_importance_vertical.tiff",
       path = "data/Output sets/Downstream", 
       width = 1620, height = 2880, device = 'tiff', units = "px",
       dpi = 700, compression = "lzw")
dev.off()

# Evaluation on the test set #####
test_all = test_set
KBZ_Entrez_list = KBZ_DE_mapped %>% dplyr::filter(adj.P.Val < 0.05) %>%
  dplyr::select(EntrezGene.ID, Gene.Symbol)
data_test = as.data.frame(t(z_test_exprs))
siggenes = intersect(colnames(data_test), KBZ_Entrez_list$EntrezGene.ID)
data_test = data_test %>% dplyr::select(all_of(siggenes))
data_test$Sample.ID = rownames(data_test)
test_all$Treatment = as.factor(test_all$Treatment)
test_all$Timepoint_coded = factor(test_all$Timepoint_coded, 
                                  levels = unique(test_all$Timepoint_coded),
                                  labels = c("T1", "T2"))
test_all = test_all %>%
  inner_join(data_test, by = "Sample.ID") %>%
  inner_join(Pheno_test %>% dplyr::select(Sample.ID, pam50, rorS_risk, scmod1, IC10,
                                          Mammaprint_risk), by = "Sample.ID") %>%
  dplyr::select(-Patient.ID, -Treatment_status, -Chemo_status, -Endo_status, -Response_type,
                -Response_coded, -Timepoint, -Platform, -Platform_comp)
str_sub(colnames(test_all)[7:172],0,0) = "X_"

# Splitting categorical variables into dummy variables
test_all = test_all %>% 
  dplyr::select(-nr, -Sample.ID)
test_all = cbind(test_all[,unchanged], 
                 as.data.frame(model.matrix(~0 + test_all$pam50 +
                                              test_all$Timepoint_coded +
                                              test_all$Treatment +
                                              test_all$IC10 +
                                              test_all$Mammaprint_risk +
                                              test_all$rorS_risk +
                                              test_all$scmod1)))

colnames(test_all) = c(unchanged, "Basal", "HER2", "LumB", "LumA",
                       "Normal", "T2", "Endo", "IC2", "IC3", "IC4",
                       "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                       "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")
test_all = test_all %>% dplyr::select(-Basal)
test_all[c("HER2", "LumB", "LumA",
           "Normal", "T2", "Endo", "IC2", "IC3", "IC4",
           "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
           "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")] = 
  lapply(test_all[c("HER2", "LumB", "LumA", "Normal", "T2", "Endo",
                    "IC2", "IC3", "IC4",
                    "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                    "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")],
         function(x) factor(x, levels = c(0,1), 
                            labels = c(0,1)))

Final_model = Best_models[["C5_ROC_gs_meta"]]
Final_model_test_predictions = predict(Final_model, test_all)
Final_model_prediction_table = table(Final_model_test_predictions, test_all$Response)
Final_model_accuracy = (Final_model_prediction_table[1] + Final_model_prediction_table[4])/
  sum(Final_model_prediction_table)

print(paste0(round(Final_model_accuracy*100, 2), 
             " % of classification accuracy on the test set")) 
# 56.71 % real responders in the test set
# 71.64 % classification accuracy (~14% improvement)

################################################################################
# External validation set preprocessing #####

# GSE18728
pdata1 = pData(Ext_val[["GSE18728"]]) %>%
  dplyr::rename(Sample.ID = geo_accession, Response = `response category:ch1`,
                Timepoint_coded = `time point:ch1`, Patient.ID = `upin:ch1`) %>%
  dplyr::select(Sample.ID, Patient.ID, Timepoint_coded, Response) %>%
  dplyr::mutate(Treatment = "Chemotherapy", Platform = "GPL570", 
                Platform_comp = "Affymetrix")
pdata1$Timepoint_coded = toupper(pdata1$Timepoint_coded)
pdata1 = pdata1 %>% dplyr::filter(!Timepoint_coded=="OR")
pdata1$Response = gsub("NR", "Non_responder", pdata1$Response, fixed = TRUE)
pdata1$Response = gsub("R", "Responder", pdata1$Response, fixed = TRUE)
pdata1$Timepoint_coded = gsub("C2", "T2", pdata1$Timepoint_coded, fixed = TRUE)
pdata1$Timepoint_coded = gsub("BL", "T1", pdata1$Timepoint_coded, fixed = TRUE)
str_sub(pdata1$Patient.ID, 0, 0) = "XVC1."
pdata1$Response = as.factor(pdata1$Response)
pdata1$Timepoint_coded = as.factor(pdata1$Timepoint_coded)
pdata1$Dataset = "XVC1"
pdata1$Treatment_status = 1
pdata1$Chemo_status = 1
pdata1$Endo_status = 0
pdata1$Timepoint = as.character(pdata1$Timepoint_coded)
pdata1$Timepoint[pdata1$Timepoint_coded == "T1"] = "Pre-treatment"
pdata1$Timepoint[pdata1$Timepoint_coded == "T2"] = "On-treatment"
pdata1$Response_coded = as.character(pdata1$Response)
pdata1$Response_coded[pdata1$Response == "Responder"] = 1
pdata1$Response_coded[pdata1$Response == "Non_responder"] = 0
pdata1$Response_type = "pCR & tumor size"

# GSE119262
pdata2 = pData(Ext_val[["GSE119262"]]) %>%
  dplyr::rename(Response = `ki67_response:ch1`, Sample.ID = geo_accession) %>%
  dplyr::select(Sample.ID, title, Response) %>%
  dplyr::mutate(Treatment = "Chemotherapy", Platform = "GPL6104",
                Platform_comp = "Illumina")
pdata2 = pdata2 %>%
  tidyr::separate(title, into = c("discard", "Patient.ID", "Timepoint_coded"),
                  sep = "[:,.]") %>%
  dplyr::select(-discard)
pre = which(grepl("Pre", pdata2$Timepoint_coded))
post = c(1:nrow(pdata2))[-pre]
pdata2$Timepoint_coded[pre] = "T1"
pdata2$Timepoint_coded[post] = "T2"; rm(pre, post)
pdata2$Patient.ID = gsub("Patient", "XVC2.", pdata2$Patient.ID)
pdata2$Response = str_to_sentence(gsub("_Ki67", "", pdata2$Response))
pdata2$Response = gsub("-", "_", pdata2$Response)
pdata2$Response = as.factor(pdata2$Response)
pdata2$Timepoint_coded = as.factor(pdata2$Timepoint_coded)
pdata2$Dataset = "XVC2"
pdata2$Treatment_status = 1
pdata2$Chemo_status = 1
pdata2$Endo_status = 0
pdata2$Timepoint = as.character(pdata2$Timepoint_coded)
pdata2$Timepoint[pdata2$Timepoint_coded == "T1"] = "Pre-treatment"
pdata2$Timepoint[pdata2$Timepoint_coded == "T2"] = "2 weeks"
pdata2$Response_coded = as.character(pdata2$Response)
pdata2$Response_coded[pdata2$Response == "Responder"] = 1
pdata2$Response_coded[pdata2$Response == "Non_responder"] = 0
pdata2$Response_type = "Ki67% drop"

# GSE111563
# Add external response metrics provided by Dr. Cigdem Selli
XVE_resp = read.csv("data/Supplementary/XVE_response.csv") %>%
  dplyr::rename(Patient.ID = `patient.no`, Response = `dormancy.status`)
str_sub(XVE_resp$Patient.ID, 0, 0) = "XVE."
XVE_resp$Response = gsub("Resistant_AR", "Non_responder", XVE_resp$Response)
XVE_resp$Response = gsub("Dormant_D", "Responder", XVE_resp$Response)
pdata3 = pData(Ext_val[["GSE111563"]]) %>%
  dplyr::rename(Sample.ID = `geo_accession`) %>% dplyr::select(Sample.ID, title) %>%
  tidyr::separate(title, into = c("discard", "Patient.ID", "Timepoint_coded"),
                  sep = "_") %>%
  dplyr::select(-discard) %>%
  dplyr::filter(!Timepoint_coded=="Timepoint4")
pdata3$Patient.ID = gsub("PatientX", "XVE.", pdata3$Patient.ID)
pdata3$Timepoint_coded = gsub("Timepoint1", "T1", pdata3$Timepoint_coded)
pdata3$Timepoint_coded = gsub("Timepoint2", "T2", pdata3$Timepoint_coded)
pdata3 = pdata3 %>% inner_join(XVE_resp, by = "Patient.ID")
pdata3$Treatment = "Endocrine_treatment"
pdata3$Platform = "GPL10558"
pdata3$Platform_comp = "Illumina"
pdata3$Response = as.factor(pdata3$Response)
pdata3$Timepoint_coded = as.factor(pdata3$Timepoint_coded)
pdata3$Dataset = "XVE"
pdata3$Treatment_status = 1
pdata3$Chemo_status = 0
pdata3$Endo_status = 1
pdata3$Timepoint = as.character(pdata3$Timepoint_coded)
pdata3$Timepoint[pdata3$Timepoint_coded == "T1"] = "Pre-treatment"
pdata3$Timepoint[pdata3$Timepoint_coded == "T2"] = "Within 2 months"
pdata3$Response_coded = as.character(pdata3$Response)
pdata3$Response_coded[pdata3$Response == "Responder"] = 1
pdata3$Response_coded[pdata3$Response == "Non_responder"] = 0
pdata3$Response_type = "US tumor size & Ki67 etc."

# Stephen-John Sammut's data (https://www.nature.com/articles/s41586-021-04278-5)
# GitHub repo: (https://github.com/cclab-brca/neoadjuvant-therapy-response-predictor)
# Here, only expression and phenotypic data are in our directory in order to load in R
# Expression data not available in GEO

# load clinical metadata (Supplementary Table 1)
metadata  = read.xlsx("data/SJS_extval/Supplementary Tables.xlsx", sheet = 1)
# combine ER and HER2 status
metadata$ERHER2.status = ifelse(metadata$ER.status=="POS","ER+ HER2-","ER- HER2-")
metadata$ERHER2.status = ifelse(metadata$HER2.status=="POS","HER2+",metadata$ERHER2.status)
metadataFull = metadata

# Perform analyses with cases that had an RCB assessment and received more than one cycle of therapy
# as detailed in Methods (Statistical testing)
metadata = metadata[metadata$RCB.category!="NA",]
# metadata = metadata[metadata$Chemo.cycles>1 & metadata$aHER2.cycles>1,]

# load Gene Ensembl ID to Entrez and Hugo ID dictionary
ensemblToHugo = read.table("data/SJS_extval/EnsemblID.to.Hugo.v87.tsv.gz", header=T, stringsAsFactors = F,sep="\t")
ensemblToEntrez = read.table("data/SJS_extval/EnsemblID.to.Entrez.tsv.gz", header=T, stringsAsFactors = F,sep="\t")

# load RNA data (Supplementary Table 3)
rnadata  = read.xlsx("data/SJS_extval/Supplementary Tables.xlsx",sheet = 3)

p = metadata

# load RNAseq raw counts (Methods)
transneo.counts = data.frame(data.table::fread(
  "data/SJS_extval/transneo-diagnosis-RNAseq-rawcounts.tsv.gz", 
  header=T, sep="\t",stringsAsFactors = F),row.names = 1)

# We need to convert to log2(TPM) and normalize
# We'll get the gene lengths (summed exon lengths) from EDASeq (hg38)
library(EDASeq)
lengthsedaseq = as.data.frame(getGeneLengthAndGCContent(ensembl_list,
                                                        "hsa", mode = "org.db")) %>%
  dplyr::filter(!is.na(length)) %>%
  mutate(Ensembl.ID = rownames(.)) %>%
  dplyr::select(-gc) %>%
  group_by(Ensembl.ID) %>%
  top_n(1, length) %>%
  inner_join(ensemblToEntrez, by = "Ensembl.ID")
ensembl_lengths = lengthsedaseq %>% dplyr::select(-EntrezGene.ID) %>% distinct()

# https://support.bioconductor.org/p/91218/#91256 - Michael Love's suggestion
# convert length to kb (Josh Starmer:
# https://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/)
sjs_expmat = as.matrix(transneo.counts[ensembl_lengths$Ensembl.ID,])
norm_sjs_expmat = sjs_expmat/(ensembl_lengths$length/1000) 
class(norm_sjs_expmat) = "numeric"
sjs_tpm = t(t(norm_sjs_expmat)*1e6/colSums(norm_sjs_expmat))
log2sjs_tpm = log2(sjs_tpm + 1)

log2sjs_tpm = log2sjs_tpm[,colnames(log2sjs_tpm) %in% p$Donor.ID[!is.na(p$pCR.RD)]]

# update metadata - retain only samples that have RNAseq data
pdata4 = p[p$Donor.ID %in% colnames(log2sjs_tpm),]
pdata4$Sample.ID = paste0("XVC3.", pdata4$Donor.ID)
pdata4$Dataset = "XVC3"
pdata4$Timepoint_coded = factor("T1", levels = "T1", labels = "T1")
pdata4$Timepoint = "Pre-treatment"
pdata4$Treatment = "Chemotherapy"
pdata4$Platform = "Illumina HiSeq4000"
pdata4$Platform_comp = "Illumina"
pdata4$Treatment_status = 1
pdata4$Chemo_status = 1
pdata4$Endo_status = 0
pdata4$Response = ifelse(pdata4$pCR.RD == "pCR", "Responder", "Non_responder")
pdata4$Response_coded = ifelse(pdata4$Response == "Responder", 1, 0)
pdata4$Response_type = "pCR/RD"
pdata4 = pdata4 %>%
  dplyr::select(Sample.ID, Patient.ID = Donor.ID, Timepoint_coded, Response,
                Treatment, Platform, Platform_comp, Dataset, Treatment_status, 
                Chemo_status, Endo_status, Timepoint, Response_coded, Response_type)

# Binding
full_ext_pdata = rbind(pdata1, pdata2, pdata4, pdata3)
full_ext_pdata$Dataset = as.factor(full_ext_pdata$Dataset)
RNGversion("4.0.2")
set.seed(123)
full_ext_pdata$nr = sample(5000:10000, nrow(full_ext_pdata))

# Imputation and annotation on the external validation sets #####

# No missing values in the external validation sets:
sum(which(is.na(Ext_val[["GSE18728"]]@assayData[["exprs"]])))  # 0
sum(which(is.na(Ext_val[["GSE119262"]]@assayData[["exprs"]]))) # 0
sum(which(is.na(Ext_val[["GSE111563"]]@assayData[["exprs"]]))) # 0
sum(which(is.na(log2sjs_tpm))) # 0


# GSE18728
feature_extval = Ext_val[["GSE18728"]]@featureData@data %>%
  dplyr::select(ID, ENTREZ_GENE_ID) %>%
  dplyr::filter(!grepl("///", ENTREZ_GENE_ID)) %>%
  dplyr::filter(!grepl(",", ENTREZ_GENE_ID)) %>% # in case there are multiple genes in a probe
  dplyr::filter(nchar(ENTREZ_GENE_ID)>0)
exprs18728_extval = as.data.frame(Ext_val[["GSE18728"]]@assayData[["exprs"]])[feature_extval$ID,]
exprs18728_extval$ID = rownames(exprs18728_extval)
exprs18728_Entrez_extval = exprs18728_extval %>%
  inner_join(feature_extval) %>%
  dplyr::select(-ID) %>%
  dplyr::select(ENTREZ_GENE_ID, everything()) %>%
  dplyr::filter(is.na(ENTREZ_GENE_ID) == FALSE) %>% # just in case
  group_by(ENTREZ_GENE_ID) %>%
  summarise_all(mean, na.rm = TRUE) %>%
  dplyr::rename(EntrezGene.ID = ENTREZ_GENE_ID)
exprs18728_Entrez_extval$EntrezGene.ID = as.character(exprs18728_Entrez_extval$EntrezGene.ID)

dannot18728_Entrez_extval = as.data.frame(exprs18728_Entrez_extval[,"EntrezGene.ID"])
dannot18728_Entrez_extval$probe = dannot18728_Entrez_extval$EntrezGene.ID
dannot18728_Entrez_extval = dannot18728_Entrez_extval %>%
  dplyr::select(probe, EntrezGene.ID)
rownames(dannot18728_Entrez_extval) = dannot18728_Entrez_extval$probe

exprs18728_HGNC_extval = exprs18728_Entrez_extval %>% inner_join(official_df, by = "EntrezGene.ID") %>%
  dplyr::select(-EntrezGene.ID, -HGNC_Official) %>%
  dplyr::select(Gene.Symbol, everything()) %>%
  group_by(Gene.Symbol) %>%
  summarise_all(mean, na.rm = TRUE)

dannot18728_HGNC_extval = as.data.frame(exprs18728_HGNC_extval[,"Gene.Symbol"])
dannot18728_HGNC_extval$probe = dannot18728_HGNC_extval$Gene.Symbol
dannot18728_HGNC_extval = dannot18728_HGNC_extval %>%
  dplyr::select(probe, Gene.Symbol)
rownames(dannot18728_HGNC_extval) = dannot18728_HGNC_extval$probe

rm(exprs18728_extval, feature_extval)

# GSE119262
feature_extval = Ext_val[["GSE119262"]]@featureData@data %>%
  dplyr::select(ID, Entrez_Gene_ID) %>%
  dplyr::filter(!grepl("///", Entrez_Gene_ID)) %>%
  dplyr::filter(!grepl(",", Entrez_Gene_ID)) %>% # in case there are multiple genes in a probe
  dplyr::filter(nchar(Entrez_Gene_ID)>0)
exprs119262_extval = as.data.frame(Ext_val[["GSE119262"]]@assayData[["exprs"]])[feature_extval$ID,]
exprs119262_extval$ID = rownames(exprs119262_extval)
exprs119262_Entrez_extval = exprs119262_extval %>%
  inner_join(feature_extval) %>%
  dplyr::select(-ID) %>%
  dplyr::select(Entrez_Gene_ID, everything()) %>%
  dplyr::filter(is.na(Entrez_Gene_ID) == FALSE) %>% # just in case
  group_by(Entrez_Gene_ID) %>%
  summarise_all(mean, na.rm = TRUE) %>%
  dplyr::rename(EntrezGene.ID = Entrez_Gene_ID)
exprs119262_Entrez_extval$EntrezGene.ID = as.character(exprs119262_Entrez_extval$EntrezGene.ID)

dannot119262_Entrez_extval = as.data.frame(exprs119262_Entrez_extval[,"EntrezGene.ID"])
dannot119262_Entrez_extval$probe = dannot119262_Entrez_extval$EntrezGene.ID
dannot119262_Entrez_extval = dannot119262_Entrez_extval %>%
  dplyr::select(probe, EntrezGene.ID)
rownames(dannot119262_Entrez_extval) = dannot119262_Entrez_extval$probe

exprs119262_HGNC_extval = exprs119262_Entrez_extval %>% inner_join(official_df, by = "EntrezGene.ID") %>%
  dplyr::select(-EntrezGene.ID, -HGNC_Official) %>%
  dplyr::select(Gene.Symbol, everything()) %>%
  group_by(Gene.Symbol) %>%
  summarise_all(mean, na.rm = TRUE)

dannot119262_HGNC_extval = as.data.frame(exprs119262_HGNC_extval[,"Gene.Symbol"])
dannot119262_HGNC_extval$probe = dannot119262_HGNC_extval$Gene.Symbol
dannot119262_HGNC_extval = dannot119262_HGNC_extval %>%
  dplyr::select(probe, Gene.Symbol)
rownames(dannot119262_HGNC_extval) = dannot119262_HGNC_extval$probe

rm(exprs119262_extval, feature_extval)

# GSE111563
feature_extval = Ext_val[["GSE111563"]]@featureData@data %>%
  dplyr::select(ID, Entrez_Gene_ID) %>%
  dplyr::filter(!grepl("///", Entrez_Gene_ID)) %>%
  dplyr::filter(!grepl(",", Entrez_Gene_ID)) %>% # in case there are multiple genes in a probe
  dplyr::filter(nchar(Entrez_Gene_ID)>0)
exprs111563_extval = as.data.frame(Ext_val[["GSE111563"]]@assayData[["exprs"]])[feature_extval$ID,]
exprs111563_extval$ID = rownames(exprs111563_extval)
exprs111563_Entrez_extval = exprs111563_extval %>%
  inner_join(feature_extval) %>%
  dplyr::select(-ID) %>%
  dplyr::select(Entrez_Gene_ID, everything()) %>%
  dplyr::filter(is.na(Entrez_Gene_ID) == FALSE) %>% # just in case
  group_by(Entrez_Gene_ID) %>%
  summarise_all(mean, na.rm = TRUE) %>%
  dplyr::rename(EntrezGene.ID = Entrez_Gene_ID)
exprs111563_Entrez_extval$EntrezGene.ID = as.character(exprs111563_Entrez_extval$EntrezGene.ID)

dannot111563_Entrez_extval = as.data.frame(exprs111563_Entrez_extval[,"EntrezGene.ID"])
dannot111563_Entrez_extval$probe = dannot111563_Entrez_extval$EntrezGene.ID
dannot111563_Entrez_extval = dannot111563_Entrez_extval %>%
  dplyr::select(probe, EntrezGene.ID)
rownames(dannot111563_Entrez_extval) = dannot111563_Entrez_extval$probe

exprs111563_HGNC_extval = exprs111563_Entrez_extval %>% inner_join(official_df, by = "EntrezGene.ID") %>%
  dplyr::select(-EntrezGene.ID, -HGNC_Official) %>%
  dplyr::select(Gene.Symbol, everything()) %>%
  group_by(Gene.Symbol) %>%
  summarise_all(mean, na.rm = TRUE)

dannot111563_HGNC_extval = as.data.frame(exprs111563_HGNC_extval[,"Gene.Symbol"])
dannot111563_HGNC_extval$probe = dannot111563_HGNC_extval$Gene.Symbol
dannot111563_HGNC_extval = dannot111563_HGNC_extval %>%
  dplyr::select(probe, Gene.Symbol)
rownames(dannot111563_HGNC_extval) = dannot111563_HGNC_extval$probe

rm(exprs111563_extval, feature_extval)

# We will later append the normalised versions of the last two datasets with rows for the 
# missing Entrez ID's filled with the zeros.

# Stephen-John Sammut's data
sjs_eset = as.data.frame(log2sjs_tpm) %>%
  mutate(Ensembl.ID = rownames(.)) %>%
  inner_join(ensemblToEntrez) %>%
  dplyr::select(-Ensembl.ID) %>%
  dplyr::select(EntrezGene.ID, everything()) %>%
  dplyr::filter(!is.na(EntrezGene.ID)) %>% # just in case
  group_by(EntrezGene.ID) %>%
  summarise_all(mean, na.rm = TRUE)
sjs_eset$EntrezGene.ID = as.character(sjs_eset$EntrezGene.ID)
colnames(sjs_eset) = c("EntrezGene.ID", pdata4$Sample.ID)

dannot_sjs_Entrez = as.data.frame(list(probe = sjs_eset$EntrezGene.ID, 
                                       EntrezGene.ID = sjs_eset$EntrezGene.ID))
rownames(dannot_sjs_Entrez) = dannot_sjs_Entrez$probe

exprs_sjs_hgnc = as.data.frame(log2sjs_tpm) %>%
  mutate(Ensembl.ID = rownames(.)) %>%
  inner_join(ensemblToHugo) %>%
  dplyr::select(-Ensembl.ID) %>%
  dplyr::select(Gene.Symbol = Hugo, everything()) %>%
  dplyr::filter(!is.na(Gene.Symbol)) %>% # just in case
  group_by(Gene.Symbol) %>%
  summarise_all(mean, na.rm = TRUE)
colnames(exprs_sjs_hgnc) = c("Gene.Symbol", pdata4$Sample.ID)

dannot_sjs_hgnc = as.data.frame(list(probe = exprs_sjs_hgnc$Gene.Symbol, 
                                     Gene.Symbol = exprs_sjs_hgnc$Gene.Symbol))
rownames(dannot_sjs_hgnc) = dannot_sjs_hgnc$probe

# Checking whether our list of genes is consistently present in the external
# datasets:
checkers = unchanged[-1]
str_sub(checkers, 0, 2) = ""
length(intersect(exprs18728_Entrez_extval$EntrezGene.ID, checkers))  # 166
length(intersect(exprs119262_Entrez_extval$EntrezGene.ID, checkers)) # 163
length(intersect(exprs111563_Entrez_extval$EntrezGene.ID, checkers)) # 150
length(intersect(sjs_eset$EntrezGene.ID, checkers)) # 166

additions119262 = checkers[!checkers %in% exprs119262_Entrez_extval$EntrezGene.ID]
additions111563 = checkers[!checkers %in% exprs111563_Entrez_extval$EntrezGene.ID]

# Genefu phenotypic annotation #####
Entrez_exprs_extval = list(exprs18728_Entrez_extval, exprs119262_Entrez_extval, 
                           exprs111563_Entrez_extval, sjs_eset)
names(Entrez_exprs_extval) = c(names(Ext_val), "XVC3")

HGNC_exprs_extval = list(exprs18728_HGNC_extval, exprs119262_HGNC_extval, 
                           exprs111563_HGNC_extval, exprs_sjs_hgnc)
names(HGNC_exprs_extval) = c(names(Ext_val), "XVC3")

dannot_Entrez_extval = list(dannot18728_Entrez_extval, dannot119262_Entrez_extval,
                              dannot111563_Entrez_extval, dannot_sjs_Entrez)
names(dannot_Entrez_extval) = c(names(Ext_val), "XVC3")

dannot_HGNC_extval = list(dannot18728_HGNC_extval, dannot119262_HGNC_extval,
                          dannot111563_HGNC_extval, dannot_sjs_hgnc)
names(dannot_HGNC_extval) = c(names(Ext_val), "XVC3")

rm(exprs111563_Entrez_extval, exprs111563_HGNC_extval, exprs119262_Entrez_extval,
   sjs_eset, exprs119262_HGNC_extval, exprs18728_Entrez_extval, exprs18728_HGNC_extval,
   exprs_sjs_hgnc, dannot111563_Entrez_extval, dannot111563_HGNC_extval, 
   dannot119262_Entrez_extval, dannot_sjs_Entrez, dannot119262_HGNC_extval, 
   dannot18728_Entrez_extval, dannot18728_HGNC_extval, dannot_sjs_hgnc)
gc()

Genefu_sets_extval = list()
for (i in 1:length(Entrez_exprs_extval)){
  genefu_set = Genefu_predictions_2(expressionDF = Entrez_exprs_extval[[i]],
                                    HGNC = HGNC_exprs_extval[[i]],
                                    dannot_Entrez = dannot_Entrez_extval[[i]],
                                    dannot_HGNC = dannot_HGNC_extval[[i]])
  Genefu_sets_extval[[i]] = genefu_set
}

rm(claudinLowData, genefu_set, pam50.robust, scmod1.robust, sig.gene70, i); gc()
names(Genefu_sets_extval) = c(names(Ext_val), "XVC3")

Genefu_megaset_extval = rbind(Genefu_sets_extval[["GSE18728"]], 
                              Genefu_sets_extval[["GSE119262"]],
                              Genefu_sets_extval[["XVC3"]], 
                              Genefu_sets_extval[["GSE111563"]])

ext_pdata = full_ext_pdata %>% inner_join(Genefu_megaset_extval, by = "Sample.ID")
ext_pdata = ext_pdata[, colnames(Pheno_test)]

write.xlsx(ext_pdata, "data/Output sets/Ext_val.xlsx", overwrite = TRUE)

# Normalisation #####
# Here, we are normalising within each study the way we did with our previous studies

# Adding the missing rows (sample means)
# GSE119262
c = Entrez_exprs_extval[["GSE119262"]][,-1]
add = cbind(additions119262, matrix(rbind(sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE))),
                                    nrow = 3, ncol = ncol(Entrez_exprs_extval[["GSE119262"]])-1))
colnames(add) = colnames(Entrez_exprs_extval[["GSE119262"]])
Entrez_exprs_extval[["GSE119262"]] = rbind(Entrez_exprs_extval[["GSE119262"]], add); rm(add)
Entrez_exprs_extval[["GSE119262"]][colnames(Entrez_exprs_extval[["GSE119262"]])[-1]] = 
  lapply(Entrez_exprs_extval[["GSE119262"]][colnames(Entrez_exprs_extval[["GSE119262"]])[-1]],
         function(x) as.numeric(x))

# GSE111563
c = Entrez_exprs_extval[["GSE111563"]][,-1]
add = cbind(additions111563, matrix(rbind(sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE)),
                                          sapply(c, function (c) mean(c, na.rm = TRUE))),
                                    nrow = 16, ncol = ncol(Entrez_exprs_extval[["GSE111563"]])-1))
colnames(add) = colnames(Entrez_exprs_extval[["GSE111563"]])
Entrez_exprs_extval[["GSE111563"]] = rbind(Entrez_exprs_extval[["GSE111563"]], add); rm(add)
Entrez_exprs_extval[["GSE111563"]][colnames(Entrez_exprs_extval[["GSE111563"]])[-1]] = 
  lapply(Entrez_exprs_extval[["GSE111563"]][colnames(Entrez_exprs_extval[["GSE111563"]])[-1]],
         function(x) as.numeric(x))

rm(c); gc()
z_extval = list()

for(i in 1:length(Entrez_exprs_extval)){
  df = as.data.frame(Entrez_exprs_extval[[i]][,2:ncol(Entrez_exprs_extval[[i]])])
  df = df[,intersect(colnames(df), ext_pdata$Sample.ID)]
  t = as.data.frame(t(df))
  z_extval_t = sapply(t, function(t) (t-mean(t, na.rm = T))/sd(t, na.rm = T))
  z_extval[[i]] = as.matrix(t(z_extval_t))
  rownames(z_extval[[i]]) = Entrez_exprs_extval[[i]]$EntrezGene.ID
  colnames(z_extval[[i]]) = colnames(df)
  z_extval[[i]] = as.data.frame(z_extval[[i]])
  z_extval[[i]]$EntrezGene.ID = Entrez_exprs_extval[[i]]$EntrezGene.ID
  rm(t, z_extval_t, df)
}
names(z_extval) = c(names(Ext_val), "XVC3")

z_extval_filt = z_extval
for(i in 1:length(z_extval_filt)){
  z_extval_filt[[i]] = z_extval_filt[[i]][z_extval_filt[[i]]$EntrezGene.ID %in% checkers,]
}

# Merging the normalised expression matrices and adding phenotypic data

ext_z_final = z_extval_filt[[1]] %>% # XVC1
  inner_join(z_extval_filt[[2]], by = "EntrezGene.ID") %>% # XVC2
  inner_join(z_extval_filt[[4]], by = "EntrezGene.ID") %>% # XVC3
  inner_join(z_extval_filt[[3]], by = "EntrezGene.ID") %>% # XVE
  dplyr::select(EntrezGene.ID, everything())
rownames(ext_z_final) = ext_z_final$EntrezGene.ID
ext_z_final = ext_z_final[,-1]

ext_data = as.data.frame(t(ext_z_final))
str_sub(colnames(ext_data),0,0) = "X_"
ext_data$Sample.ID = rownames(ext_data)
ext_data = ext_data %>% inner_join(ext_pdata %>% 
                                     dplyr::select(Sample.ID, pam50, rorS_risk, scmod1, IC10,
                                                   Mammaprint_risk, Treatment, Response,
                                                   Timepoint_coded), by = "Sample.ID")

# Splitting categorical variables into dummy variables
ext_data = ext_data %>% 
  dplyr::select(-Sample.ID)
ext_data = cbind(ext_data[,unchanged], 
                 as.data.frame(model.matrix(~0 + ext_data$pam50 +
                                              ext_data$Timepoint_coded +
                                              ext_data$Treatment +
                                              ext_data$IC10 +
                                              ext_data$Mammaprint_risk +
                                              ext_data$rorS_risk +
                                              ext_data$scmod1)))

colnames(ext_data) = c(unchanged, "Basal", "HER2", "LumB", "LumA",
                       "Normal", "T2", "Endo", "IC2", "IC3", "IC4",
                       "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                       "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")
ext_data = ext_data %>% dplyr::select(-Basal)
ext_data[c("HER2", "LumB", "LumA",
           "Normal", "T2", "Endo", "IC2", "IC3", "IC4",
           "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
           "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")] = 
  lapply(ext_data[c("HER2", "LumB", "LumA", "Normal", "T2", "Endo",
                    "IC2", "IC3", "IC4",
                    "IC5", "IC6", "IC7", "IC8", "IC9", "IC10", "Mammaprint_risk_yes",
                    "rorS_risk_interm", "rorS_risk_high", "ER_hp", "ER_lp", "HER2_scmod1")],
         function(x) factor(x, levels = c(0,1), 
                            labels = c(0,1)))
ext_data$Response = factor(ext_data$Response, levels = c("Responder", "Non_responder"),
                           labels = c("Responder", "Non_responder"))

Final_model_extval_predictions = predict(Final_model, ext_data)
Final_model_extval_prediction_table = table(Final_model_extval_predictions, ext_data$Response)
Final_model_extval_accuracy = (Final_model_extval_prediction_table[1] + 
                                 Final_model_extval_prediction_table[4])/
  sum(Final_model_extval_prediction_table)

print(paste0(round(Final_model_extval_accuracy*100, 2), 
             " % of classification accuracy on the external validation set"))

# 63.66 % accuracy on the external validation data
# 44.77 % proportion of responders in the ext. validation set

#                      Responder     Non_responder
# Responder            83            54
# Non_responder        71           136

# Annotation of samples with actual ER+ status #####
ann = as.data.frame(rbind(train_set[,c("Sample.ID", "Dataset")], 
            validation_set[,c("Sample.ID", "Dataset")], 
            test_set[,c("Sample.ID", "Dataset")],
            ext_pdata[,c("Sample.ID", "Dataset")]))

ER_annot = as.data.frame(cbind(ann, as.data.frame(rbind(as.data.frame(Training[["All_together"]]) %>% 
                                               dplyr::select(-Cluster_2), 
                               as.data.frame(Validation[["All_together"]]) %>% 
                                               dplyr::select(-Cluster_2),
                 test_all, ext_data))))

rm(ann); gc()

# Additional ER annotation
# C1 
c1erpos = openxlsx::read.xlsx("data/Supplementary/C1.Response.xlsx", sheet = 1) %>%
  dplyr::select(Patient.ID = Demographic.ID, ER_pre = ER)
c1erpos$Patient.ID = gsub(" \\(left side\\)", "", c1erpos$Patient.ID)
c1_subset = ER_annot[ER_annot$Dataset == "C1",]
patients = c1_subset$Sample.ID
str_sub(patients, -3, -1) = ""
c1_subset$Patient.ID = patients
c1_subset = c1_subset %>% left_join(c1erpos, by = "Patient.ID")
c1_subset$ER_num = as.numeric(gsub("7 \\& 8", "8", c1_subset$ER_pre))
c1_subset$ER_status = ifelse(c1_subset$ER_num < 5, "Neg", "Pos")
ER_add = c1_subset %>% dplyr::select(Sample.ID, ER_status)
rm(c1erpos, c1_subset); gc()

# C2
library(readr)
library(GEOquery)
readr::local_edition(1) # required for v>=2.60.0 of GEOquery

c2pdata = pData(unlist(getGEO("GSE32603")[[1]]))
c2pdata_filt = c2pdata %>%
  dplyr::select(Sample.ID = geo_accession, ER_code = `hr-positive_yes is 1:ch1`) %>%
  mutate(ER_status = ifelse(ER_code == 1, "Pos", "Neg")) %>%
  dplyr::select(-ER_code)

ER_add = rbind(ER_add, c2pdata_filt); rm(c2pdata, c2pdata_filt); gc()

# C3
c3pdata = pData(getGEO('GSE123845',GSEMatrix=TRUE)[[1]])
c3pdata_filt = c3pdata %>%
  dplyr::select(Sample.ID = geo_accession, ER_code = `er_status_diagnosis:ch1`) %>%
  mutate(ER_status = ifelse(ER_code == 1, "Pos", "Neg")) %>%
  dplyr::select(-ER_code)
ER_add = rbind(ER_add, c3pdata_filt); rm(c3pdata, c3pdata_filt); gc()

# XVC1
xvc1erpos = pData(Ext_val[["GSE18728"]])
xvc1erpos_filt = xvc1erpos %>%
  dplyr::select(Sample.ID = geo_accession, ER_code = `er original:ch1`) %>%
  mutate(ER_status = ifelse(ER_code == "neg", "Neg", "Pos")) %>%
  dplyr::select(-ER_code)
ER_add = rbind(ER_add, xvc1erpos_filt); rm(xvc1erpos, xvc1erpos_filt); gc()

# XVC3
sjserpos = p[p$Donor.ID %in% colnames(log2sjs_tpm),]
sjserpos$Sample.ID = paste0("XVC3.", sjserpos$Donor.ID)
sjserpos$ER.status = str_to_sentence(sjserpos$ER.status) 
sjserpos = sjserpos %>% 
  dplyr::rename(ER_status = ER.status) %>%
  dplyr::select(Sample.ID, ER_status)
ER_add = rbind(ER_add, sjserpos); rm(sjserpos); gc()

ER_add = rbind(ER_add, 
               list(Sample.ID = ER_annot$Sample.ID[ER_annot$Dataset == "E1_1"], 
                    ER_status = rep("Pos", 
                                    length(ER_annot$Sample.ID[ER_annot$Dataset == "E1_1"]))),
               list(Sample.ID = ER_annot$Sample.ID[ER_annot$Dataset == "E1_2"], 
                    ER_status = rep("Pos", 
                                    length(ER_annot$Sample.ID[ER_annot$Dataset == "E1_2"]))),
               list(Sample.ID = ER_annot$Sample.ID[ER_annot$Dataset == "E1_3"], 
                    ER_status = rep("Pos", 
                                    length(ER_annot$Sample.ID[ER_annot$Dataset == "E1_3"]))),
               list(Sample.ID = ER_annot$Sample.ID[ER_annot$Dataset == "E2"], 
                    ER_status = rep("Pos", 
                                    length(ER_annot$Sample.ID[ER_annot$Dataset == "E2"]))),
               list(Sample.ID = ER_annot$Sample.ID[ER_annot$Dataset == "E3"], 
                    ER_status = rep("Pos", 
                                    length(ER_annot$Sample.ID[ER_annot$Dataset == "E3"]))),
               list(Sample.ID = ER_annot$Sample.ID[ER_annot$Dataset == "E4_1"], 
                    ER_status = rep("Pos", 
                                    length(ER_annot$Sample.ID[ER_annot$Dataset == "E4_1"]))),
               list(Sample.ID = ER_annot$Sample.ID[ER_annot$Dataset == "E4_2"], 
                    ER_status = rep("Pos", 
                                    length(ER_annot$Sample.ID[ER_annot$Dataset == "E4_2"]))),
               list(Sample.ID = ER_annot$Sample.ID[ER_annot$Dataset == "XVC2"], 
                    ER_status = rep("Pos", 
                                    length(ER_annot$Sample.ID[ER_annot$Dataset == "XVC2"]))),
               list(Sample.ID = ER_annot$Sample.ID[ER_annot$Dataset == "XVE"], 
                    ER_status = rep("Pos", 
                                    length(ER_annot$Sample.ID[ER_annot$Dataset == "XVE"])))
                    )

ER_annot = ER_annot %>% dplyr::left_join(ER_add, by = "Sample.ID")
ER_annot = as.data.frame(ER_annot)

# Subsets
ER_annot_train = ER_annot %>% dplyr::filter(ER_status == "Pos") %>%
  dplyr::filter(Sample.ID %in% train_set$Sample.ID)
ER_annot_val = ER_annot %>% dplyr::filter(ER_status == "Pos") %>%
  dplyr::filter(Sample.ID %in% validation_set$Sample.ID)
ER_annot_test = ER_annot %>% dplyr::filter(ER_status == "Pos") %>%
  dplyr::filter(Sample.ID %in% test_set$Sample.ID)
ER_annot_xvc1 = ER_annot %>% dplyr::filter(ER_status == "Pos") %>%
  dplyr::filter(Sample.ID %in% pdata1$Sample.ID)
ER_annot_xvc2 = ER_annot %>% dplyr::filter(ER_status == "Pos") %>%
  dplyr::filter(Sample.ID %in% pdata2$Sample.ID)
ER_annot_xve = ER_annot %>% dplyr::filter(ER_status == "Pos") %>%
  dplyr::filter(Sample.ID %in% pdata3$Sample.ID)
ER_annot_sjs = ER_annot %>% dplyr::filter(ER_status == "Pos") %>%
  dplyr::filter(Sample.ID %in% pdata4$Sample.ID)

# ROC plots #####
# predictions
model = Final_model
preds_train = predict(model, Training[["All_together"]], type = "prob")
preds_val = predict(model, Validation[["All_together"]], type = "prob")
preds_test = predict(model, test_all, type = "prob")
preds_extval = predict(model, ext_data, type = "prob")
preds_extval_1 = predict(model, ext_data[1:39,], type = "prob") # GSE18728 - chemo
preds_extval_2 = predict(model, ext_data[40:127,], type = "prob") # GSE119262 - chemo
preds_extval_4 = predict(model, ext_data[128:282,], type = "prob") # XVC3 - chemo
preds_extval_3 = predict(model, ext_data[283:344,], type = "prob") # GSE111563 - endo
preds_train_HER2 = predict(model, Training[["All_together"]][Training[["All_together"]]$HER2==1,], type = "prob")
preds_val_HER2 = predict(model, Validation[["All_together"]][Validation[["All_together"]]$HER2==1,], type = "prob")
preds_test_HER2 = predict(model, test_all[test_all$HER2 == 1,], type = "prob")
preds_extval_HER2 = predict(model, ext_data[ext_data$HER2 == 1,], type = "prob")
preds_train_Basal = predict(model, Training[["All_together"]][Training[["All_together"]]$LumA==0 &
                                                                Training[["All_together"]]$LumB==0 &
                                                                Training[["All_together"]]$Normal==0 &
                                                                Training[["All_together"]]$HER2==0,], type = "prob")
preds_val_Basal = predict(model, Validation[["All_together"]][Validation[["All_together"]]$LumA==0 &
                                                                Validation[["All_together"]]$LumB==0 &
                                                                Validation[["All_together"]]$Normal==0 &
                                                                Validation[["All_together"]]$HER2==0,], type = "prob")
preds_test_Basal = predict(model, test_all[test_all$LumA == 0 &
                                             test_all$LumB == 0 &
                                             test_all$Normal == 0 &
                                             test_all$HER2 == 0,], type = "prob")
preds_extval_Basal = predict(model, ext_data[ext_data$LumA == 0 &
                                               ext_data$LumB == 0 &
                                               ext_data$Normal == 0 &
                                               ext_data$HER2 == 0,], type = "prob")
preds_train_ERpos = predict(model, Training[["All_together"]][Training[["All_together"]]$LumA==1 |
                                                                Training[["All_together"]]$LumB==1 |
                                                                Training[["All_together"]]$Normal==1,], type = "prob")
preds_val_ERpos = predict(model, Validation[["All_together"]][Validation[["All_together"]]$LumA==1 |
                                                                Validation[["All_together"]]$LumB==1 |
                                                                Validation[["All_together"]]$Normal==1,], type = "prob")
preds_test_ERpos = predict(model, test_all[test_all$LumA == 1 |
                                             test_all$LumB == 1 |
                                             test_all$Normal == 1,], type = "prob")
preds_extval_ERpos = predict(model, ext_data[ext_data$LumA == 1 |
                                               ext_data$LumB == 1 |
                                               ext_data$Normal == 1,], type = "prob")
preds_extval_1_ERpos = predict(model, ext_data[1:39,] %>%
                                 dplyr::filter(LumA == 1 |
                                               LumB == 1 |
                                               Normal == 1), type = "prob")
preds_extval_2_ERpos = predict(model, ext_data[40:127,] %>%
                                 dplyr::filter(LumA == 1 |
                                                 LumB == 1 |
                                                 Normal == 1), type = "prob")
preds_extval_4_ERpos = predict(model, ext_data[128:282,] %>%
                                 dplyr::filter(LumA == 1 |
                                                 LumB == 1 |
                                                 Normal == 1), type = "prob")
preds_extval_3_ERpos = predict(model, ext_data[283:344,] %>%
                                 dplyr::filter(LumA == 1 |
                                                 LumB == 1 |
                                                 Normal == 1), type = "prob")
preds_train_actual_ERpos = predict(model, ER_annot_train, type = "prob") 
preds_val_actual_ERpos = predict(model, ER_annot_val, type = "prob")
preds_test_actual_ERpos = predict(model, ER_annot_test, type = "prob")
preds_xvc1_actual_ERpos = predict(model, ER_annot_xvc1, type = "prob")
preds_xvc2_actual_ERpos = predict(model, ER_annot_xvc2, type = "prob")
preds_xve_actual_ERpos = predict(model, ER_annot_xve, type = "prob")
preds_sjs_actual_ERpos = predict(model, ER_annot_sjs, type = "prob")

# Joins
join_train = cbind(preds_train, Training[["All_together"]])
join_train = join_train[order(join_train$Responder),]
join_val = cbind(preds_val, Validation[["All_together"]])
join_val = join_val[order(join_val$Responder),]
join_test = cbind(preds_test, test_all)
join_test = join_test[order(join_test$Responder),]
join_extval = cbind(preds_extval, ext_data)
join_extval = join_extval[order(join_extval$Responder),]
join_extval_1 = cbind(preds_extval_1, ext_data[1:39,])
join_extval_1 = join_extval_1[order(join_extval_1$Responder),]
join_extval_2 = cbind(preds_extval_2, ext_data[40:127,])
join_extval_2 = join_extval_2[order(join_extval_2$Responder),]
join_extval_4 = cbind(preds_extval_4, ext_data[128:282,])
join_extval_4 = join_extval_4[order(join_extval_4$Responder),]
join_extval_3 = cbind(preds_extval_3, ext_data[283:344,])
join_extval_3 = join_extval_3[order(join_extval_3$Responder),]
join_train_HER2 = cbind(preds_train_HER2, Training[["All_together"]][Training[["All_together"]]$HER2==1,])
join_train_HER2 = join_train_HER2[order(join_train_HER2$Responder),]
join_val_HER2 = cbind(preds_val_HER2, Validation[["All_together"]][Validation[["All_together"]]$HER2==1,])
join_val_HER2 = join_val_HER2[order(join_val_HER2$Responder),]
join_test_HER2 = cbind(preds_test_HER2, test_all[test_all$HER2==1,])
join_test_HER2 = join_test_HER2[order(join_test_HER2$Responder),]
join_extval_HER2 = cbind(preds_extval_HER2, ext_data[ext_data$HER2==1,])
join_extval_HER2 = join_extval_HER2[order(join_extval_HER2$Responder),]
join_train_Basal = cbind(preds_train_Basal, Training[["All_together"]][Training[["All_together"]]$LumA==0 &
                                                                         Training[["All_together"]]$LumB==0 &
                                                                         Training[["All_together"]]$Normal==0 &
                                                                         Training[["All_together"]]$HER2==0,])
join_train_Basal = join_train_Basal[order(join_train_Basal$Responder),]
join_val_Basal = cbind(preds_val_Basal, Validation[["All_together"]][Validation[["All_together"]]$LumA==0 &
                                                                       Validation[["All_together"]]$LumB==0 &
                                                                       Validation[["All_together"]]$Normal==0 &
                                                                       Validation[["All_together"]]$HER2==0,])
join_val_Basal = join_val_Basal[order(join_val_Basal$Responder),]
join_test_Basal = cbind(preds_test_Basal, test_all[test_all$LumA == 0 &
                                                     test_all$LumB == 0 &
                                                     test_all$Normal == 0 &
                                                     test_all$HER2 == 0,])
join_test_Basal = join_test_Basal[order(join_test_Basal$Responder),]
join_extval_Basal = cbind(preds_extval_Basal, ext_data[ext_data$LumA == 0 &
                                                         ext_data$LumB == 0 &
                                                         ext_data$Normal == 0 &
                                                         ext_data$HER2 == 0,])
join_extval_Basal = join_extval_Basal[order(join_extval_Basal$Responder),]
join_train_ERpos = cbind(preds_train_ERpos, Training[["All_together"]][Training[["All_together"]]$LumA==1 |
                                                                         Training[["All_together"]]$LumB==1 |
                                                                         Training[["All_together"]]$Normal==1,])
join_train_ERpos = join_train_ERpos[order(join_train_ERpos$Responder),]
join_val_ERpos = cbind(preds_val_ERpos, Validation[["All_together"]][Validation[["All_together"]]$LumA==1 |
                                                                       Validation[["All_together"]]$LumB==1 |
                                                                       Validation[["All_together"]]$Normal==1,])
join_val_ERpos = join_val_ERpos[order(join_val_ERpos$Responder),]
join_test_ERpos = cbind(preds_test_ERpos, test_all[test_all$LumA == 1 |
                                                     test_all$LumB == 1 |
                                                     test_all$Normal == 1,])
join_test_ERpos = join_test_ERpos[order(join_test_ERpos$Responder),]
join_extval_ERpos = cbind(preds_extval_ERpos, ext_data[ext_data$LumA == 1 |
                                                         ext_data$LumB == 1 |
                                                         ext_data$Normal == 1,])
join_extval_ERpos = join_extval_ERpos[order(join_extval_ERpos$Responder),]
join_extval_1_ERpos = cbind(preds_extval_1_ERpos, ext_data[1:39,] %>%
                              dplyr::filter(LumA == 1 |
                                              LumB == 1 |
                                              Normal == 1))
join_extval_2_ERpos = cbind(preds_extval_2_ERpos, ext_data[40:127,] %>%
                              dplyr::filter(LumA == 1 |
                                              LumB == 1 |
                                              Normal == 1))
join_extval_4_ERpos = cbind(preds_extval_4_ERpos, ext_data[128:282,] %>%
                              dplyr::filter(LumA == 1 |
                                              LumB == 1 |
                                              Normal == 1))
join_extval_3_ERpos = cbind(preds_extval_3_ERpos, ext_data[283:344,] %>%
                              dplyr::filter(LumA == 1 |
                                              LumB == 1 |
                                              Normal == 1))
join_train_actual_ERpos = cbind(preds_train_actual_ERpos, ER_annot_train)
join_train_actual_ERpos = join_train_actual_ERpos[order(join_train_actual_ERpos$Responder),]
join_val_actual_ERpos = cbind(preds_val_actual_ERpos, ER_annot_val)
join_val_actual_ERpos = join_val_actual_ERpos[order(join_val_actual_ERpos$Responder),]
join_test_actual_ERpos = cbind(preds_test_actual_ERpos, ER_annot_test)
join_test_actual_ERpos = join_test_actual_ERpos[order(join_test_actual_ERpos$Responder),]
join_xvc1_actual_ERpos = cbind(preds_xvc1_actual_ERpos, ER_annot_xvc1)
join_xvc1_actual_ERpos = join_xvc1_actual_ERpos[order(join_xvc1_actual_ERpos$Responder),]
join_xvc2_actual_ERpos = cbind(preds_xvc2_actual_ERpos, ER_annot_xvc2)
join_xvc2_actual_ERpos = join_xvc2_actual_ERpos[order(join_xvc2_actual_ERpos$Responder),]
join_xve_actual_ERpos = cbind(preds_xve_actual_ERpos, ER_annot_xve)
join_xve_actual_ERpos = join_xve_actual_ERpos[order(join_xve_actual_ERpos$Responder),]
join_sjs_actual_ERpos = cbind(preds_sjs_actual_ERpos, ER_annot_sjs)
join_sjs_actual_ERpos = join_sjs_actual_ERpos[order(join_sjs_actual_ERpos$Responder),]

# ROC estimation
model_roc_train = roc(predictor = join_train$Responder, response = as.character(join_train$Response))
model_roc_val = roc(predictor = join_val$Responder, response = as.character(join_val$Response))
model_roc_test = roc(predictor = join_test$Responder, response = as.character(join_test$Response))
model_roc_extval = roc(predictor = join_extval$Responder, response = as.character(join_extval$Response))
model_roc_extval_1 = roc(predictor = join_extval_1$Responder, response = as.character(join_extval_1$Response))
model_roc_extval_2 = roc(predictor = join_extval_2$Responder, response = as.character(join_extval_2$Response))
model_roc_extval_3 = roc(predictor = join_extval_3$Responder, response = as.character(join_extval_3$Response))
model_roc_extval_4 = roc(predictor = join_extval_4$Responder, response = as.character(join_extval_4$Response))
model_roc_train_HER2 = roc(predictor = join_train_HER2$Responder, response = as.character(join_train_HER2$Response))
model_roc_val_HER2 = roc(predictor = join_val_HER2$Responder, response = as.character(join_val_HER2$Response))
model_roc_test_HER2 = roc(predictor = join_test_HER2$Responder, response = as.character(join_test_HER2$Response))
model_roc_extval_HER2 = roc(predictor = join_extval_HER2$Responder, response = as.character(join_extval_HER2$Response))
model_roc_train_Basal = roc(predictor = join_train_Basal$Responder, response = as.character(join_train_Basal$Response))
model_roc_val_Basal = roc(predictor = join_val_Basal$Responder, response = as.character(join_val_Basal$Response))
model_roc_test_Basal = roc(predictor = join_test_Basal$Responder, response = as.character(join_test_Basal$Response))
model_roc_extval_Basal = roc(predictor = join_extval_Basal$Responder, response = as.character(join_extval_Basal$Response))
model_roc_train_ERpos = roc(predictor = join_train_ERpos$Responder, response = as.character(join_train_ERpos$Response))
model_roc_val_ERpos = roc(predictor = join_val_ERpos$Responder, response = as.character(join_val_ERpos$Response))
model_roc_test_ERpos = roc(predictor = join_test_ERpos$Responder, response = as.character(join_test_ERpos$Response))
model_roc_extval_ERpos = roc(predictor = join_extval_ERpos$Responder, response = as.character(join_extval_ERpos$Response))
model_roc_extval_1_ERpos = roc(predictor = join_extval_1_ERpos$Responder, response = as.character(join_extval_1_ERpos$Response))
model_roc_extval_2_ERpos = roc(predictor = join_extval_2_ERpos$Responder, response = as.character(join_extval_2_ERpos$Response))
model_roc_extval_3_ERpos = roc(predictor = join_extval_3_ERpos$Responder, response = as.character(join_extval_3_ERpos$Response))
model_roc_extval_4_ERpos = roc(predictor = join_extval_4_ERpos$Responder, response = as.character(join_extval_4_ERpos$Response))
model_roc_train_actual_ERpos = roc(predictor = join_train_actual_ERpos$Responder, 
                                   response = as.character(join_train_actual_ERpos$Response))
model_roc_val_actual_ERpos = roc(predictor = join_val_actual_ERpos$Responder, 
                                 response = as.character(join_val_actual_ERpos$Response))
model_roc_test_actual_ERpos = roc(predictor = join_test_actual_ERpos$Responder, 
                                  response = as.character(join_test_actual_ERpos$Response))
model_roc_xvc1_actual_ERpos = roc(predictor = join_xvc1_actual_ERpos$Responder, 
                                  response = as.character(join_xvc1_actual_ERpos$Response))
model_roc_xvc2_actual_ERpos = roc(predictor = join_xvc2_actual_ERpos$Responder, 
                                  response = as.character(join_xvc2_actual_ERpos$Response))
model_roc_xve_actual_ERpos = roc(predictor = join_xve_actual_ERpos$Responder, 
                                 response = as.character(join_xve_actual_ERpos$Response))
model_roc_sjs_actual_ERpos = roc(predictor = join_sjs_actual_ERpos$Responder, 
                                 response = as.character(join_sjs_actual_ERpos$Response))

# AUC
AUC_train = round(auc(model_roc_train), 3)
AUC_val = round(auc(model_roc_val), 3)
AUC_test = round(auc(model_roc_test), 3)
AUC_extval = round(auc(model_roc_extval), 3)
AUC_extval_1 = round(auc(model_roc_extval_1), 3)
AUC_extval_2 = round(auc(model_roc_extval_2), 3)
AUC_extval_3 = round(auc(model_roc_extval_3), 3)
AUC_extval_4 = round(auc(model_roc_extval_4), 3)
AUC_train_HER2 = round(auc(model_roc_train_HER2), 3)
AUC_val_HER2 = round(auc(model_roc_val_HER2), 3)
AUC_test_HER2 = round(auc(model_roc_test_HER2), 3)
AUC_extval_HER2 = round(auc(model_roc_extval_HER2), 3)
AUC_train_Basal = round(auc(model_roc_train_Basal), 3)
AUC_val_Basal = round(auc(model_roc_val_Basal), 3)
AUC_test_Basal = round(auc(model_roc_test_Basal), 3)
AUC_extval_Basal = round(auc(model_roc_extval_Basal), 3)
AUC_train_ERpos = round(auc(model_roc_train_ERpos), 3)
AUC_val_ERpos = round(auc(model_roc_val_ERpos), 3)
AUC_test_ERpos = round(auc(model_roc_test_ERpos), 3)
AUC_extval_ERpos = round(auc(model_roc_extval_ERpos), 3)
AUC_extval_1_ERpos = round(auc(model_roc_extval_1_ERpos), 3)
AUC_extval_2_ERpos = round(auc(model_roc_extval_2_ERpos), 3)
AUC_extval_3_ERpos = round(auc(model_roc_extval_3_ERpos), 3)
AUC_extval_4_ERpos = round(auc(model_roc_extval_4_ERpos), 3)
AUC_train_actual_ERpos = round(auc(model_roc_train_actual_ERpos), 3)
AUC_val_actual_ERpos = round(auc(model_roc_val_actual_ERpos), 3)
AUC_test_actual_ERpos = round(auc(model_roc_test_actual_ERpos), 3)
AUC_xvc1_actual_ERpos = round(auc(model_roc_xvc1_actual_ERpos), 3)
AUC_xvc2_actual_ERpos = round(auc(model_roc_xvc2_actual_ERpos), 3)
AUC_xve_actual_ERpos = round(auc(model_roc_xve_actual_ERpos), 3)
AUC_sjs_actual_ERpos = round(auc(model_roc_sjs_actual_ERpos), 3)

# Plotting the AUCs #####
library(rcartocolor) # for colorblind-appropriate palettes
# display_carto_all(colorblind_friendly = TRUE)
roc_palette_safe = carto_pal(n = 7, name = "Safe")
val_col = roc_palette_safe[1]
test_col = roc_palette_safe[2]
extval1_col = roc_palette_safe[3]
extval2_col = roc_palette_safe[4]
extval3_col = roc_palette_safe[5]
extval4_col = roc_palette_safe[6]
full_extval_col = roc_palette_safe[7]
  
# Double ROC (validation and test)
tiff("data/Output sets/Downstream/Validation_ROC_plots/Final_model_double_ROC.tiff",
     width = 1920, height = 1920, res = 700, compression = "lzw")
plot(model_roc_val, # AUC = 0.814
     main = "ROC curves for the C5.0-ROC-optimized classifier", adj = 0.65,
     col = val_col, lwd = 1, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, cex.main = 0.6, xaxs = "i", yaxs = "i", cex.axis = 0.5, cex.lab = 0.5,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity'))))
plot(model_roc_test, col = test_col, lwd = 1, add = TRUE) # AUC = 0.787
# Add a legend
legend(0.3, 0.25, legend=c("Validation", "Test"),
       col=c(val_col, test_col), lty=1, lwd = 1, cex=0.3)
dev.off()
rm(model, preds_train, preds_val, preds_test, preds_extval, join_train, join_val, join_test,
   join_extval)

# Triple ROC (validation, test, ext. validation)
tiff("data/Output sets/Downstream/Validation_ROC_plots/Final_model_triple_ROC.tiff",
     width = 1920, height = 1920, res = 700, compression = "lzw")
plot(model_roc_val, # AUC = 0.814
     main = "ROC curves for the C5.0-ROC-optimized classifier", adj = 0.65,
     col = val_col, lwd = 1, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, cex.main = 0.6, xaxs = "i", yaxs = "i", cex.axis = 0.5, cex.lab = 0.5,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity'))))
plot(model_roc_test, col = test_col, lwd = 1, add = TRUE) # AUC = 0.787
plot(model_roc_extval, col = full_extval_col, lwd = 1, add = TRUE) # AUC = 0.645
# Add a legend
legend(0.35, 0.35, legend=c("Validation", "Test", "Ext. validation"),
       col=c(val_col, test_col, full_extval_col), lty=1, lwd = 1, cex=0.3)
dev.off()

# Quadruple ROC (external validation subsets)
tiff("data/Output sets/Downstream/Validation_ROC_plots/Extval_subsets_quadruple_ROC.tiff",
     width = 1920, height = 1920, res = 700, compression = "lzw")
plot(model_roc_extval_1, # AUC = 0.864
     main = "ROC curves for the external validation subsets", adj = 0.65,
     col = extval1_col, lwd = 1, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, cex.main = 0.6, xaxs = "i", yaxs = "i", cex.axis = 0.5, cex.lab = 0.5,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity'))))
plot(model_roc_extval_2, col = extval2_col, lwd = 1, add = TRUE) # AUC = 0.536
plot(model_roc_extval_4, col = extval4_col, lwd = 1, add = TRUE) # AUC = 0.642
plot(model_roc_extval_3, col = extval3_col, lwd = 1, add = TRUE) # AUC = 0.564
# Add a legend
legend(0.35, 0.35, legend=c("XVC1", "XVC2", "XVC3", "XVE"),
       col=c(extval1_col, extval2_col, extval4_col, extval3_col), lty=1, lwd = 1, cex=0.3)
dev.off()

# Sextuple ROC full (Validation, Test, Broken external validation)
tiff("data/Output sets/Downstream/Validation_ROC_plots/Six_ROC.tiff",
     width = 1920, height = 1920, res = 700, compression = "lzw")
plot(model_roc_val, # AUC = 0.814
     main = "ROC curves for all subsets", adj = 0.65,
     col = val_col, lwd = 1, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, cex.main = 0.6, xaxs = "i", yaxs = "i", cex.axis = 0.5, cex.lab = 0.5,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity'))))
plot(model_roc_test, col = test_col, lwd = 1, add = TRUE) # AUC = 0.787
plot(model_roc_extval_1, col = extval1_col, lwd = 1, add = TRUE) # AUC = 0.864
plot(model_roc_extval_2, col = extval2_col, lwd = 1, add = TRUE) # AUC = 0.536
plot(model_roc_extval_4, col = extval4_col, lwd = 1, add = TRUE) # AUC = 0.642
plot(model_roc_extval_3, col = extval3_col, lwd = 1, add = TRUE) # AUC = 0.564
# Add a legend
legend(0.3, 0.5, legend=c("Validation", "Test", "XVC1", "XVC2", "XVC3", "XVE"),
       col=c(val_col, test_col, extval1_col, extval2_col, extval4_col, extval3_col),
       lty=1, lwd = 1, cex=0.3)
dev.off()

# Sextuple ROC genefu ER+ only (Validation, Test, Broken external validation)
tiff("data/Output sets/Downstream/Validation_ROC_plots/genefu_ER_positive_Sextuple_ROC.tiff",
     width = 1920, height = 1920, res = 700, compression = "lzw")
plot(model_roc_val_ERpos, # AUC = 0.855
     main = "ROC curves for genefu ER+ samples", adj = 0.65,
     col = val_col, lwd = 1, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, cex.main = 0.6, xaxs = "i", yaxs = "i", cex.axis = 0.5, cex.lab = 0.5,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity'))))
plot(model_roc_test_ERpos, col = test_col, lwd = 1, add = TRUE) # AUC = 0.795
plot(model_roc_extval_1_ERpos, col = extval1_col, lwd = 1, add = TRUE) # AUC = 0.864
plot(model_roc_extval_2_ERpos, col = extval2_col, lwd = 1, add = TRUE) # AUC = 0.574
plot(model_roc_extval_4_ERpos, col = extval4_col, lwd = 1, add = TRUE) # AUC = 0.822
plot(model_roc_extval_3_ERpos, col = extval3_col, lwd = 1, add = TRUE) # AUC = 0.559
# Add a legend
legend(0.3, 0.5, legend=c("Validation", "Test", "XVC1", "XVC2", "XVC3", "XVE"),
       col=c(val_col, test_col, extval1_col, extval2_col, extval4_col, extval3_col),
       lty=1, lwd = 1, cex=0.3)
dev.off()

# Sextuple ROC actual ER+ only (Validation, Test, Broken external validation)
tiff("data/Output sets/Downstream/Validation_ROC_plots/ER_positive_actual_Sextuple_ROC.tiff",
     width = 1920, height = 1920, res = 700, compression = "lzw")
plot(model_roc_val_actual_ERpos, # AUC = 0.822
     main = "ROC curves for ER+ tumor samples", adj = 0.65,
     col = val_col, lwd = 1, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, cex.main = 0.6, xaxs = "i", yaxs = "i", cex.axis = 0.5, cex.lab = 0.5,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity'))))
plot(model_roc_test_actual_ERpos, col = test_col, lwd = 1, add = TRUE) # AUC = 0.785
plot(model_roc_xvc1_actual_ERpos, col = extval1_col, lwd = 1, add = TRUE) # AUC = 0.885
plot(model_roc_xvc2_actual_ERpos, col = extval2_col, lwd = 1, add = TRUE) # AUC = 0.536
plot(model_roc_sjs_actual_ERpos, col = extval4_col, lwd = 1, add = TRUE) # AUC = 0.693
plot(model_roc_xve_actual_ERpos, col = extval3_col, lwd = 1, add = TRUE) # AUC = 0.564
# Add a legend
legend(0.3, 0.5, legend=c("Validation", "Test", "XVC1", "XVC2", "XVC3", "XVE"),
       col=c(val_col, test_col, extval1_col, extval2_col, extval4_col, extval3_col),
       lty=1, lwd = 1, cex=0.3)
dev.off()

# Figure 5a
# Quintuple ROC full (Test, Broken external validation)
tiff("data/Output sets/Downstream/Validation_ROC_plots/Quintuple_ROC.tiff",
     width = 84, height = 84, res = 650, units = "mm", compression = "lzw")
plot(model_roc_test, 
     # main = "ROC curves for all samples",
     main = "", # no title
     col = test_col, lwd = 1.25, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, # cex.main = 0.5, 
     cex.lab = 0.6, xaxs = "i", yaxs = "i", cex.axis = 0.7,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity')))) # AUC = 0.787
plot(model_roc_extval_1, col = extval1_col, lwd = 1.25, add = TRUE) # 0.864
plot(model_roc_extval_2, col = extval2_col, lwd = 1.25, add = TRUE) # 0.536
plot(model_roc_extval_4, col = extval4_col, lwd = 1.25, add = TRUE) # 0.642
plot(model_roc_extval_3, col = extval3_col, lwd = 1.25, add = TRUE) # 0.564
# Add a legend
legend(0.25, 0.35, legend=c("Test", "XVC1", "XVC2", "XVC3", "XVE"),
       col=c(test_col, extval1_col, extval2_col, extval4_col, extval3_col),
       lty=1, lwd = 1.25, cex=0.4)
dev.off()

# Figure 5b
# Quintuple ROC genefu ER+ only (Test, Broken external validation)
tiff("data/Output sets/Downstream/Validation_ROC_plots/genefu_ER_positive_Quintuple_ROC.tiff",
     width = 84, height = 84, res = 650, units = "mm", compression = "lzw")
plot(model_roc_test_ERpos, 
     # main = "ROC curves for genefu ER+ samples",
     main = "", # no title
     col = test_col, lwd = 1.25, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, # cex.main = 0.5, 
     cex.lab = 0.6, xaxs = "i", yaxs = "i", cex.axis = 0.7,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity')))) # AUC = 0.795
plot(model_roc_extval_1_ERpos, col = extval1_col, lwd = 1.25, add = TRUE) # 0.864
plot(model_roc_extval_2_ERpos, col = extval2_col, lwd = 1.25, add = TRUE) # 0.574
plot(model_roc_extval_4_ERpos, col = extval4_col, lwd = 1.25, add = TRUE) # 0.822
plot(model_roc_extval_3_ERpos, col = extval3_col, lwd = 1.25, add = TRUE) # 0.559
# Add a legend
legend(0.25, 0.35, legend=c("Test", "XVC1", "XVC2", "XVC3", "XVE"),
       col=c(test_col, extval1_col, extval2_col, extval4_col, extval3_col),
       lty=1, lwd = 1.25, cex=0.4)
dev.off()

# Figure 5b (potential)
# Quintuple ROC actual ER+ only (Test, Broken external validation)
tiff("data/Output sets/Downstream/Validation_ROC_plots/ER_positive_actual_Quintuple_ROC.tiff",
     width = 84, height = 84, res = 650, units = "mm", compression = "lzw")
plot(model_roc_test_actual_ERpos, 
     col = test_col, lwd = 1.25, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, xaxs = "i", yaxs = "i", cex.axis = 0.7, cex.lab = 0.6,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity')))) # AUC = 0.785
plot(model_roc_xvc1_actual_ERpos, col = extval1_col, lwd = 1.25, add = TRUE) # 0.885
plot(model_roc_xvc2_actual_ERpos, col = extval2_col, lwd = 1.25, add = TRUE) # 0.536
plot(model_roc_sjs_actual_ERpos, col = extval4_col, lwd = 1.25, add = TRUE) # 0.693
plot(model_roc_xve_actual_ERpos, col = extval3_col, lwd = 1.25, add = TRUE) # 0.564
# Add a legend
legend(0.25, 0.35, legend=c("Test", "XVC1", "XVC2", "XVC3", "XVE"),
       col=c(test_col, extval1_col, extval2_col, extval4_col, extval3_col),
       lty=1, lwd = 1.25, cex=0.4)
dev.off()

# Triple ROC (HER2+)
tiff("data/Output sets/Downstream/Validation_ROC_plots/genefu_HER2_subsets_triple_ROC.tiff",
     width = 1920, height = 1920, res = 700, compression = "lzw")
plot(model_roc_val_HER2, # AUC = 0.787
     main = "ROC curves for the genefu HER2+ subsets", adj = 0.65,
     col = val_col, lwd = 1, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, cex.main = 0.6, xaxs = "i", yaxs = "i", cex.axis = 0.5, cex.lab = 0.5,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity'))))
plot(model_roc_test_HER2, col = test_col, lwd = 1, add = TRUE) # AUC = 0.781
plot(model_roc_extval_HER2, col = full_extval_col, lwd = 1, add = TRUE) # AUC = 0.606
# Add a legend
legend(0.35, 0.35, legend=c("Validation", "Test", "Ext. validation"),
       col=c(val_col, test_col, full_extval_col), lty=1, lwd = 1, cex=0.3)
dev.off()

# Triple ROC (Basal)
tiff("data/Output sets/Downstream/Validation_ROC_plots/genefu_Basal_subsets_triple_ROC.tiff",
     width = 1920, height = 1920, res = 700, compression = "lzw")
plot(model_roc_val_Basal, # AUC = 0.577
     main = "ROC curves for the genefu Basal subsets", adj = 0.65,
     col = val_col, lwd = 1, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, cex.main = 0.6, xaxs = "i", yaxs = "i", cex.axis = 0.5, cex.lab = 0.5,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity'))))
plot(model_roc_test_Basal, col = test_col, lwd = 1, add = TRUE) # AUC = 0.650
plot(model_roc_extval_Basal, col = full_extval_col, lwd = 1, add = TRUE) # AUC = 0.481
# Add a legend
legend(0.35, 0.35, legend=c("Validation", "Test", "Ext. validation"),
       col=c(val_col, test_col, full_extval_col), lty=1, lwd = 1, cex=0.3)
dev.off()

# Triple ROC (ER+)
tiff("data/Output sets/Downstream/Validation_ROC_plots/genefu_ER_positive_subsets_triple_ROC.tiff",
     width = 1920, height = 1920, res = 700, compression = "lzw")
plot(model_roc_val_ERpos, # AUC = 0.855
     main = "ROC curves for the genefu ER+ (Luminal A, Luminal B, Normal) subsets", adj = 0.65,
     col = val_col, lwd = 1, legacy.axes = TRUE, xlim = c(1,0), ylim = c(0,1), 
     asp = 1, cex.main = 0.45, xaxs = "i", yaxs = "i", cex.axis = 0.5, cex.lab = 0.5,
     xlab = substitute(paste(bold('1 - Specificity'))),
     ylab = substitute(paste(bold('Sensitivity'))))
plot(model_roc_test_ERpos, col = test_col, lwd = 1, add = TRUE) # AUC = 0.795
plot(model_roc_extval_ERpos, col = full_extval_col, lwd = 1, add = TRUE) # AUC = 0.689
# Add a legend
legend(0.35, 0.35, legend=c("Validation", "Test", "Ext. validation"),
       col=c(val_col, test_col, full_extval_col), lty=1, lwd = 1, cex=0.3)
dev.off()

################################################################################
# Pathway and Network analysis with pathfindR #####
library(pathfindR)

# Visualisations of pathways have been moved to a folder outside the repository
# due to large size and difficulties with uploading to GitHub
gene_sets = c("BioCarta", "GO-BP", "GO-CC", "GO-MF", "KEGG", "Reactome")

# Loading the input to pathfindR (the stage 1 vs normal topTable output):
input = KBZ_DE_mapped %>%
  dplyr::select(Gene.Symbol, logFC, adj.P.Val) %>%
  na.omit()

# Preparing a pathfindR loop for enrichment analysis
dirs = paste0("pathfindR/", gene_sets)
pathfindR_outputs = list()

RNGversion("4.0.2")
set.seed(123)
for (i in 1:length(dirs)){
  pathfindR_outputs[[i]] = run_pathfindR(input, gene_sets = gene_sets[i],
                                         p_val_threshold = 0.05, 
                                         visualize_enriched_terms = TRUE,
                                         output_dir = dirs[i], min_gset_size = 10,
                                         max_gset_size = 300, adj_method = 'fdr',
                                         enrichment_threshold = 0.05,
                                         pin_name_path = 'Biogrid', search_method = 'GR',
                                         grMaxDepth = 1, grSearchDepth = 1,
                                         iterations = 10, n_processes = 10)
  cat(paste0("Done with ", gene_sets[i], "\n"))
}
names(pathfindR_outputs) = gene_sets

# Perform hierarchical clustering on the results (average distance metric)
# Not run for GO-BP and Reactome because the algorithm time complexity is O(n^3)

cluster_names = c("BioCarta", "GO-BP", "GO-CC", "GO-MF", "KEGG", "Reactome")
RNGversion("4.0.2")
set.seed(123)
clustered_results = list()
for (i in 1:length(cluster_names)){
  clustered_results[[i]] = cluster_enriched_terms(pathfindR_outputs[[cluster_names[[i]]]],
                                                  method = "hierarchical")
}
names(clustered_results) = cluster_names

# BioCarta : The maximum average silhouette width was 0.75 for k = 15
# GO-BP    : The maximum average silhouette width was 0.48 for k = 39 
# GO-CC    : The maximum average silhouette width was 0.35 for k = 30
# GO-MF    : The maximum average silhouette width was 0.36 for k = 22
# KEGG     : The maximum average silhouette width was 0.54 for k = 48
# Reactome : The maximum average silhouette width was 0.83 for k = 167

# Wrapping the text of terms with too many characters in their description
wrapped_pathfindR_outputs = pathfindR_outputs
for (i in 1:length(wrapped_pathfindR_outputs)){
  wrapped_pathfindR_outputs[[i]]$Term_Description = stringr::str_wrap(pathfindR_outputs[[i]]$Term_Description, 
                                                                      width = 41)
}
rm(i)

wrapped_clustered_pathfindR_outputs = clustered_results
for (i in 1:length(wrapped_clustered_pathfindR_outputs)){
  wrapped_clustered_pathfindR_outputs[[i]]$Term_Description = stringr::str_wrap(clustered_results[[i]]$Term_Description, 
                                                                                width = 41)
}
rm(i)

enrichment_dotplots = list()
cluster_enrichment_dotplots = list()

# Producing dotplots with the results
for (i in 1:length(pathfindR_outputs)){
  # unclustered results
  enrichment_dotplots[[i]] = enrichment_chart(result_df = wrapped_pathfindR_outputs[[i]],
                                              top_terms = 10) +
    scale_color_gradient(low = "#fca4a4", high = "#fc0303")+
    scale_size(range = c(0.1, 2)) +
    theme(plot.title = element_text(size = 6, face = "bold", vjust = 2),
          plot.title.position = "panel",
          axis.text.y = element_text(color = "black", size = 4),
          axis.text.x = element_text(color = "black", size = 4),
          axis.title.x = element_text(size = 5, face = "bold"),
          legend.key.size = unit(1.5, units = "mm"),
          legend.spacing.y = unit(0.5, units = "mm"),
          legend.spacing.x = unit(0.5, units = "mm"),
          legend.title = element_text(size = 4, face = "bold"),
          legend.text = element_text(size = 3))+
    labs(title = paste0("Top 10 ", names(pathfindR_outputs)[i],
    " terms enrichment dotplot"), color = bquote(bold(-log[10](p))))
  print(enrichment_dotplots[[i]])
  ggsave(filename = paste0(names(pathfindR_outputs)[i], "_top10_dotplot.tiff"),
         path = paste0("pathfindR/", names(pathfindR_outputs)[i], "/"),
         width = 2880, height = 1620, device = 'tiff', units = "px",
         dpi = 700, compression = "lzw")
  dev.off()
  
  # clustered results
  cluster_enrichment_dotplots[[i]] = enrichment_chart(result_df = wrapped_clustered_pathfindR_outputs[[names(pathfindR_outputs)[i]]][wrapped_clustered_pathfindR_outputs[[names(pathfindR_outputs)[i]]]$Status
                                                                                                                   == "Representative", ][1:10,],
                                                      top_terms = NULL,
                                                      plot_by_cluster = TRUE)+
    scale_color_gradient(low = "#fca4a4", high = "#fc0303")+
    scale_size(range = c(0.1, 2)) +
    theme(plot.title = element_text(size = 6, face = "bold", vjust = 2),
          plot.title.position = "panel",
          axis.text.y = element_text(color = "black", size = 4),
          axis.text.x = element_text(color = "black", size = 4),
          axis.title.x = element_text(size = 5, face = "bold"),
          legend.key.size = unit(1.5, units = "mm"),
          legend.spacing.y = unit(0.5, units = "mm"),
          legend.spacing.x = unit(0.5, units = "mm"),
          legend.title = element_text(size = 4, face = "bold"),
          legend.text = element_text(size = 3))+
    labs(title = paste0("Top 10 clustered ", names(pathfindR_outputs)[i],
                        " terms enrichment dotplot"), color = bquote(bold(-log[10](p))))
  print(cluster_enrichment_dotplots[[i]])
  ggsave(filename = paste0(names(pathfindR_outputs)[i], "_top10_dotplot_clustered.tiff"),
         path = paste0("pathfindR/", names(pathfindR_outputs)[i], "/"),
         width = 2880, height = 1620, device = 'tiff', units = "px",
         dpi = 700, compression = "lzw")
  dev.off()
}

names(enrichment_dotplots) = names(pathfindR_outputs)
names(cluster_enrichment_dotplots) = names(enrichment_dotplots)

# Write out results in a comprehensive .xlsx file
wb = createWorkbook()
addWorksheet(wb, "BioCarta")
writeData(wb, "BioCarta", clustered_results[["BioCarta"]])
addWorksheet(wb, "GO-BP")
writeData(wb, "GO-BP", pathfindR_outputs[["GO-BP"]])
addWorksheet(wb, "GO-CC")
writeData(wb, "GO-CC", pathfindR_outputs[["GO-CC"]])
addWorksheet(wb, "GO-MF")
writeData(wb, "GO-MF", pathfindR_outputs[["GO-MF"]])
addWorksheet(wb, "KEGG")
writeData(wb, "KEGG", clustered_results[["KEGG"]])
addWorksheet(wb, "Reactome")
writeData(wb, "Reactome", pathfindR_outputs[["Reactome"]])
saveWorkbook(wb, file = "pathfindR/Comprehensive_pathfindR_output.xlsx",
             overwrite = TRUE); rm(wb)

# Representative terms output file (BioCarta, GO-CC, GO-MF & KEGG)
wb2 = createWorkbook()
addWorksheet(wb2, "BioCarta - rep")
writeData(wb2, "BioCarta - rep", clustered_results[["BioCarta"]][clustered_results[["BioCarta"]]$Status
                                                                 == "Representative", ])
addWorksheet(wb2, "GOBP - rep")
writeData(wb2, "GOBP - rep", clustered_results[["GO-BP"]][clustered_results[["GO-BP"]]$Status
                                                          == "Representative", ])
addWorksheet(wb2, "GOCC - rep")
writeData(wb2, "GOCC - rep", clustered_results[["GO-CC"]][clustered_results[["GO-CC"]]$Status
                                                          == "Representative", ])
addWorksheet(wb2, "GOMF - rep")
writeData(wb2, "GOMF - rep", clustered_results[["GO-MF"]][clustered_results[["GO-MF"]]$Status
                                                          == "Representative", ])
addWorksheet(wb2, "KEGG - rep")
writeData(wb2, "KEGG - rep", clustered_results[["KEGG"]][clustered_results[["KEGG"]]$Status
                                                         == "Representative", ])
addWorksheet(wb2, "Reactome - rep")
writeData(wb2, "Reactome - rep", clustered_results[["Reactome"]][clustered_results[["Reactome"]]$Status
                                                         == "Representative", ])
saveWorkbook(wb2, file = "pathfindR/Representative_terms.xlsx",
             overwrite = TRUE); rm(wb2)

# Term-gene heatmaps and term-gene graphs #####
# Plotting
term_gene_heatmaps = list()
term_gene_graphs = list()

for (i in 1:length(pathfindR_outputs)){
  # term-gene heatmaps
  term_gene_heatmaps[[i]] = term_gene_heatmap(result_df = wrapped_pathfindR_outputs[[i]],
                                              genes_df = input,
                                              num_terms = 10,
                                              use_description = TRUE,
                                              low = "darkblue",
                                              high = "red",
                                              mid = "black")+
    theme(plot.title = element_text(size = 6, face = "bold", vjust = 2),
          axis.text.y = element_text(color = "black", size = 3.5),
          axis.text.x = element_text(color = "black", size = 5,  vjust = 0.5),
          axis.title.x = element_text(size = 5, face = "bold"),
          legend.key.size = unit(3, units = "mm"),
          legend.spacing.y = unit(0.5, units = "mm"),
          legend.spacing.x = unit(0.5, units = "mm"),
          legend.title = element_text(size = 4, face = "bold"),
          legend.text = element_text(size = 4),
          legend.title.align = 0.5,
          legend.direction = "vertical") +
    scale_fill_gradient2(name = "Differential\nExpression",
                        low = "darkblue", mid = "black", na.value = "white",
                        high = "red") +
    labs(title = paste0("Top 10 ", names(pathfindR_outputs)[i], 
                        " terms - differentially expressed genes heatmap"))
  print(ggdraw(align_legend(term_gene_heatmaps[[i]], hjust = 0.5)))
  ggsave(filename = paste0(names(pathfindR_outputs)[i], "_top10_term_gene_heatmap.tiff"),
         path = paste0("pathfindR/", names(pathfindR_outputs)[i], "/"),
         width = 2880, height = 1620, device = 'tiff', units = "px",
         dpi = 700, compression = "lzw")
  dev.off()
  
  # term-gene graphs
  term_gene_graphs[[i]] = term_gene_graph(result_df = pathfindR_outputs[[i]],
                                          num_terms = 5,
                                          use_description = TRUE,
                                          node_size = "p_val")+
    aes(max.overlaps = 2)+
    scale_size(range = c(1, 3)) +
    suppressWarnings(ggraph::geom_node_text(ggplot2::aes_(label = ~name),  nudge_y = .1,
                                            repel = TRUE, size = 1, max.overlaps = 10, check_overlap = T))+
    theme(plot.title = element_text(size = 6, face = "bold", hjust = 0.5, vjust = 0.5),
          plot.background = element_rect(fill = "white"),
          plot.subtitle = element_text(size = 4.5, face = "italic", hjust = 0.5, vjust = 1.5),
          legend.key.size = unit(2, units = "mm"),
          legend.spacing.y = unit(0.5, units = "mm"),
          legend.spacing.x = unit(0.5, units = "mm"),
          legend.title = element_text(size = 4, face = "bold"),
          legend.text = element_text(size = 4),
          legend.title.align = 0.5,
          legend.direction = "vertical")
  term_gene_graphs[[i]]$layers = list(term_gene_graphs[[i]]$layers[[1]], 
                                      term_gene_graphs[[i]]$layers[[2]], 
                                      term_gene_graphs[[i]]$layers[[4]])
  print(term_gene_graphs[[i]])
  ggsave(filename = paste0(names(pathfindR_outputs)[i], "_top5_term_gene_graph.tiff"),
         path = paste0("pathfindR/", names(pathfindR_outputs)[i], "/"),
         width = 2880, height = 1620, device = 'tiff', units = "px",
         dpi = 700, compression = "lzw")
  dev.off()
}

# UpSet plots #####
UpSet_plots = list()
for (i in 1:length(pathfindR_outputs)){
  # Upset plots
  UpSet_plots[[i]] = UpSet_plot(result_df = pathfindR_outputs[[i]],
                                genes_df = input,
                                num_terms = 10,
                                use_description = TRUE,
                                low = "green",
                                high = "red",
                                mid = "black")+
    theme(axis.text.y = element_text(size = 3),
          legend.key.size = unit(2, units = "mm"),
          legend.spacing.y = unit(0.5, units = "mm"),
          legend.spacing.x = unit(0.5, units = "mm"),
          legend.title = element_text(size = 4, face = "bold"),
          legend.text = element_text(size = 4),
          legend.title.align = 0.5,
          legend.direction = "vertical")+
    ggupset::theme_combmatrix(combmatrix.panel.point.color.fill = "black",
                     combmatrix.panel.point.size = 0.8,
                     combmatrix.panel.line.size = 0.5)+
    labs(fill = "Differential\nExpression")
  tiff(paste0("pathfindR/", names(pathfindR_outputs)[i], "/",
              names(pathfindR_outputs)[i], "_top10_UpSet_plot.tiff"), 
       width = 2880, height = 1620, res = 700, compression = "lzw")
  print(UpSet_plots[[i]])
  dev.off()
}

names(term_gene_graphs) = names(pathfindR_outputs)
names(term_gene_heatmaps) = names(pathfindR_outputs)
names(UpSet_plots) = names(pathfindR_outputs)

# Per sample pathway scores #####
responders = Pheno_trainval$Sample.ID[Pheno_trainval$Response == "Responder"]
non_responders = Pheno_trainval$Sample.ID[Pheno_trainval$Response == "Non_responder"]
z_exprs_gs = z_exprs
gene_symbols = KBZ_DE_mapped[rownames(z_exprs),]
rownames(z_exprs_gs) = gene_symbols$Gene.Symbol

# Raw output
raw_score_matrices = list()
for (p in 1:length(pathfindR_outputs)){
  tiff(paste0("pathfindR/", names(pathfindR_outputs)[p], "/",
              names(pathfindR_outputs)[p], "_per_sample_pathway_scores.tif"), 
       width = 5760, height = 2160, res = 250)
  raw_score_matrices[[p]] = score_terms(enrichment_table = wrapped_pathfindR_outputs[[p]][1:10,],
                              exp_mat = z_exprs_gs,
                              cases = responders,
                              use_description = TRUE, # default FALSE
                              label_samples = FALSE, # default = TRUE
                              case_title = "Responders",  # default = "Case"
                              control_title = "Non-responders", # default = "Control"
                              low = "darkblue", # default = "green"
                              mid = "white", # default = "black"
                              high = "darkred") # default = "red"
  dev.off()
}

# Clustered terms
clustered_score_matrices = list()
for (p in 1:length(pathfindR_outputs)){
  tiff(paste0("pathfindR/", names(pathfindR_outputs)[p], "/",
              names(pathfindR_outputs)[p], "_per_sample_pathway_scores_clustered.tif"), 
       width = 5760, height = 2160, res = 250)
  clustered_score_matrices[[p]] = score_terms(enrichment_table = wrapped_clustered_pathfindR_outputs[[p]][wrapped_clustered_pathfindR_outputs[[p]]$Status == "Representative",][1:10,], 
                                        exp_mat = z_exprs_gs,
                                        cases = responders,
                                        use_description = TRUE, # default FALSE
                                        label_samples = FALSE, # default = TRUE
                                        case_title = "Responders",  # default = "Case"
                                        control_title = "Non-responders", # default = "Control"
                                        low = "darkblue", # default = "green"
                                        mid = "white", # default = "black"
                                        high = "darkred") # default = "red"
  dev.off()
}

# For ER samples only - BioCarta
p = 1
ER = intersect(Pheno_exprs$Sample.ID[
  Pheno_exprs$pam50 == "LumA" | 
    Pheno_exprs$pam50 == "LumB" | 
    Pheno_exprs$pam50 == "Normal"], colnames(z_exprs_gs))
tiff(paste0("pathfindR/", names(pathfindR_outputs)[p], "/",
            names(pathfindR_outputs)[p], "_per_sample_pathway_scores_ER_resp_non_resp.tif"), 
     width = 5760, height = 2160, res = 250)
plot = score_terms(enrichment_table = wrapped_pathfindR_outputs[[p]][1:10,],
                   exp_mat = z_exprs_gs[,ER],
                   cases = intersect(responders, ER),
                   use_description = TRUE, # default FALSE
                   label_samples = FALSE, # default = TRUE
                   case_title = "Responders",  # default = "Case"
                   control_title = "Non-responders", # default = "Control"
                   low = "darkblue", # default = "green"
                   mid = "white", # default = "black"
                   high = "darkred") # default = "red"
dev.off()

tiff(paste0("pathfindR/", names(pathfindR_outputs)[p], "/",
            names(pathfindR_outputs)[p], "_per_sample_pathway_scores_ER_all.tif"), 
     width = 5760, height = 2160, res = 250)
plot2 = score_terms(enrichment_table = wrapped_pathfindR_outputs[[p]][1:10,],
                    exp_mat = z_exprs_gs,
                    cases = ER,
                    use_description = TRUE, # default FALSE
                    label_samples = FALSE, # default = TRUE
                    case_title = "ER+",  # default = "Case"
                    control_title = "ER-", # default = "Control"
                    low = "green", # default = "green"
                    mid = "white", # default = "black"
                    high = "darkred") # default = "red"
dev.off()

# Code for vertical facet wrap plotting
plot_scores_vertical = function(score_matrix, cases = NULL, label_samples = TRUE,
                                 case_title = "Case",
                                 control_title = "Control",
                                 low = "green", mid = "black", high = "red") {
  
  #### Argument Checks
  if (!is.matrix(score_matrix)) {
    stop("`score_matrix` should be a matrix")
  }
  
  if (!is.null(cases)) {
    if (!is.atomic(cases)) {
      stop("`cases` should be a vector")
    }
    
    if (!all(cases %in% colnames(score_matrix))) {
      stop("Missing `cases` in `score_matrix`")
    }
  }
  
  if (!is.logical(label_samples)) {
    stop("`label_samples` should be TRUE or FALSE")
  }
  
  if (!is.character(case_title) | length(case_title) != 1) {
    stop("`case_title` should be a single character value")
  }
  
  if (!is.character(control_title) | length(control_title) != 1) {
    stop("`control_title` should be a single character value")
  }
  
  
  #### Create plot
  ## sort according to activity (up/down)
  if (!is.null(cases)) {
    tmp = rowMeans(score_matrix[, cases, drop = FALSE])
    score_matrix = score_matrix[c(which(tmp >= 0), which(tmp < 0)), ]
  }
  
  ## transform the matrix
  var_names = list()
  var_names[["Term"]] = factor(rownames(score_matrix),
                                levels = rev(rownames(score_matrix)))
  var_names[["Sample"]] = factor(colnames(score_matrix),
                                  levels = colnames(score_matrix))
  
  score_df = expand.grid(var_names,
                          KEEP.OUT.ATTRS = FALSE,
                          stringsAsFactors = FALSE)
  scores = as.vector(score_matrix)
  scores = data.frame(scores)
  score_df = cbind(score_df, scores)
  if (!is.null(cases)) {
    score_df$Type = ifelse(score_df$Sample %in% cases, case_title, control_title)
    score_df$Type = factor(score_df$Type,
                            levels = c(case_title, control_title))
  }
  
  g = ggplot2::ggplot(score_df, ggplot2::aes_(x = ~Sample, y = ~Term))
  g = g + ggplot2::geom_tile(ggplot2::aes_(fill = ~scores), color = "white")
  g = g + ggplot2::scale_fill_gradient2(low = low, mid = mid, high = high)
  g = g + ggplot2::theme(axis.title.x = ggplot2::element_blank(),
                          axis.title.y = ggplot2::element_blank(),
                          axis.text.x = ggplot2::element_text(angle = 45,
                                                              hjust = 1),
                          legend.title = ggplot2::element_text(size = 10),
                          legend.text = ggplot2::element_text(size = 12))
  g = g + ggplot2::labs(fill = "Score")
  if (!is.null(cases)) {
    g = g + ggplot2::facet_wrap(~Type, scales = "free", nrow = 2)
    g = g + ggplot2::theme(strip.text.x = ggplot2::element_text(size = 12,
                                                                 face = "bold"))
  }
  if (!label_samples) {
    g = g + ggplot2::theme(axis.text.x = ggplot2::element_blank(),
                            axis.ticks.x = ggplot2::element_blank())
  }
  return(g)
}

# Raw output - vertical plots
vertical_raw_score_matrices = list()
for (p in 1:length(pathfindR_outputs)){
  tiff(paste0("pathfindR/", names(pathfindR_outputs)[p], "/",
              names(pathfindR_outputs)[p], "_per_sample_pathway_scores_vertical.tif"), 
       width = 5760, height = 2160, res = 250)
  vertical_raw_score_matrices[[p]] = score_terms(enrichment_table = wrapped_pathfindR_outputs[[p]][1:10,],
                                                       exp_mat = z_exprs_gs,
                                                       cases = responders,
                                                       use_description = TRUE,
                                                       plot_hmap = FALSE)
  print(plot_scores_vertical(vertical_raw_score_matrices[[p]], cases = responders,
                             label_samples = FALSE,
                             case_title = "Responders",
                             control_title = "Non-responders",
                             low = "darkblue", mid = "white", high = "darkred"))
  dev.off()
}

# Clustered terms - vertical plots
vertical_clustered_score_matrices = list()
for (p in 1:length(pathfindR_outputs)){
  tiff(paste0("pathfindR/", names(pathfindR_outputs)[p], "/",
              names(pathfindR_outputs)[p], "_per_sample_pathway_scores_clustered_vertical.tif"), 
       width = 5760, height = 2160, res = 250)
  vertical_clustered_score_matrices[[p]] = score_terms(enrichment_table = wrapped_clustered_pathfindR_outputs[[p]][wrapped_clustered_pathfindR_outputs[[p]]$Status == "Representative",][1:10,],
                                        exp_mat = z_exprs_gs,
                                        cases = responders,
                                        use_description = TRUE,
                                        plot_hmap = FALSE)
  print(plot_scores_vertical(vertical_clustered_score_matrices[[p]], cases = responders,
                             label_samples = FALSE,
                             case_title = "Responders",
                             control_title = "Non-responders",
                             low = "darkblue", mid = "white", high = "darkred"))
  dev.off()
}

sessionInfo()
